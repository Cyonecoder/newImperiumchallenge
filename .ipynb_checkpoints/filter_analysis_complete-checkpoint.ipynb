{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trading Filter Analysis: Robustness & Improvement Study\n",
    "\n",
    "## Objective\n",
    "Identify simple, interpretable filters (volatility regimes, time windows, trend context, spread/volume filters) that could meaningfully improve trading performance while explicitly addressing overfitting risk.\n",
    "\n",
    "## Methodology\n",
    "1. **Baseline Analysis**: Establish current performance metrics\n",
    "2. **Filter Discovery**: Test 50+ filter combinations\n",
    "3. **Statistical Validation**: T-tests, Chi-square tests, effect sizes\n",
    "4. **Walk-Forward Validation**: 60/40 chronological split\n",
    "5. **Bootstrap Confidence Intervals**: Quantify uncertainty\n",
    "6. **5-Minute Candle Backtest**: Validate on high-resolution data\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(\"Libraries loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load trades data\n",
    "# Update this path to your data location\n",
    "TRADES_PATH = 'trades_with_clusters.csv'  # or full path\n",
    "CANDLES_PATH = 'XAUUSD_5min_candles.csv'  # or full path\n",
    "\n",
    "# Load trades\n",
    "df = pd.read_csv(TRADES_PATH)\n",
    "df['entry_time'] = pd.to_datetime(df['entry_time'])\n",
    "df['exit_time'] = pd.to_datetime(df['exit_time'])\n",
    "df['entry_hour'] = df['entry_time'].dt.hour\n",
    "df['entry_dayofweek'] = df['entry_time'].dt.dayofweek\n",
    "\n",
    "print(f\"Trades loaded: {len(df)} records\")\n",
    "print(f\"Date range: {df['entry_time'].min()} to {df['entry_time'].max()}\")\n",
    "print(f\"Clusters: {sorted(df['cluster'].unique())}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define trading sessions\n",
    "def get_session(hour):\n",
    "    \"\"\"Categorize hour into trading session\"\"\"\n",
    "    if 0 <= hour < 8:\n",
    "        return 'Asian'\n",
    "    elif 8 <= hour < 13:\n",
    "        return 'London'\n",
    "    elif 13 <= hour < 17:\n",
    "        return 'NY'\n",
    "    else:\n",
    "        return 'Late_NY'\n",
    "\n",
    "df['session'] = df['entry_hour'].apply(get_session)\n",
    "\n",
    "# Calculate Bollinger Band position\n",
    "df['bb_position'] = (df['entry_Close'] - df['entry_BB_Lower']) / (df['entry_BB_Upper'] - df['entry_BB_Lower'])\n",
    "\n",
    "# Add win/loss flag\n",
    "df['is_winner'] = df['profit'] > 0\n",
    "\n",
    "print(\"\\nSession distribution:\")\n",
    "print(df['session'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Baseline Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall baseline metrics\n",
    "print(\"=\"*80)\n",
    "print(\"BASELINE PERFORMANCE SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_trades = len(df)\n",
    "total_profit = df['profit'].sum()\n",
    "avg_profit = df['profit'].mean()\n",
    "win_rate = df['is_winner'].mean() * 100\n",
    "profit_std = df['profit'].std()\n",
    "\n",
    "print(f\"\\nTotal Trades: {total_trades}\")\n",
    "print(f\"Total Profit: ${total_profit:.2f}\")\n",
    "print(f\"Average Profit: ${avg_profit:.2f}\")\n",
    "print(f\"Win Rate: {win_rate:.1f}%\")\n",
    "print(f\"Profit Std Dev: ${profit_std:.2f}\")\n",
    "print(f\"Sharpe-like Ratio: {avg_profit/profit_std:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by cluster\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY CLUSTER\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cluster_stats = df.groupby('cluster').agg({\n",
    "    'profit': ['count', 'sum', 'mean', 'std'],\n",
    "    'is_winner': 'mean'\n",
    "}).round(2)\n",
    "\n",
    "cluster_stats.columns = ['Trades', 'Total_Profit', 'Avg_Profit', 'Std_Dev', 'Win_Rate']\n",
    "cluster_stats['Win_Rate'] = (cluster_stats['Win_Rate'] * 100).round(1)\n",
    "cluster_stats = cluster_stats.reset_index()\n",
    "cluster_stats['cluster'] = cluster_stats['cluster'].astype(int)\n",
    "\n",
    "print(cluster_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize baseline performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1. Profit distribution\n",
    "ax1 = axes[0, 0]\n",
    "ax1.hist(df['profit'], bins=40, color='steelblue', edgecolor='black', alpha=0.7)\n",
    "ax1.axvline(x=0, color='red', linestyle='--', linewidth=2, label='Break-even')\n",
    "ax1.axvline(x=avg_profit, color='green', linestyle='-', linewidth=2, label=f'Mean: ${avg_profit:.2f}')\n",
    "ax1.set_xlabel('Profit ($)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "ax1.set_title('Overall Profit Distribution')\n",
    "ax1.legend()\n",
    "\n",
    "# 2. Performance by cluster\n",
    "ax2 = axes[0, 1]\n",
    "colors = ['#3498db', '#e67e22', '#27ae60', '#e74c3c']\n",
    "bars = ax2.bar(cluster_stats['cluster'].astype(str), cluster_stats['Avg_Profit'], color=colors)\n",
    "ax2.axhline(y=avg_profit, color='red', linestyle='--', label=f'Overall: ${avg_profit:.2f}')\n",
    "ax2.set_xlabel('Cluster')\n",
    "ax2.set_ylabel('Average Profit ($)')\n",
    "ax2.set_title('Average Profit by Cluster')\n",
    "for bar, wr in zip(bars, cluster_stats['Win_Rate']):\n",
    "    ax2.annotate(f'WR: {wr}%', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                xytext=(0, 5), textcoords='offset points', ha='center', fontsize=10)\n",
    "ax2.legend()\n",
    "\n",
    "# 3. Equity curve\n",
    "ax3 = axes[1, 0]\n",
    "df_sorted = df.sort_values('entry_time').reset_index(drop=True)\n",
    "df_sorted['cum_profit'] = df_sorted['profit'].cumsum()\n",
    "ax3.plot(df_sorted['entry_time'], df_sorted['cum_profit'], color='steelblue', linewidth=2)\n",
    "ax3.fill_between(df_sorted['entry_time'], 0, df_sorted['cum_profit'], alpha=0.3)\n",
    "ax3.axhline(y=0, color='red', linestyle='--', alpha=0.5)\n",
    "ax3.set_xlabel('Date')\n",
    "ax3.set_ylabel('Cumulative Profit ($)')\n",
    "ax3.set_title('Equity Curve (All Trades)')\n",
    "ax3.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "\n",
    "# 4. Win rate by session\n",
    "ax4 = axes[1, 1]\n",
    "session_order = ['Asian', 'London', 'NY', 'Late_NY']\n",
    "session_stats = df.groupby('session').agg({\n",
    "    'profit': 'mean',\n",
    "    'is_winner': 'mean'\n",
    "}).reindex(session_order)\n",
    "\n",
    "x = np.arange(len(session_order))\n",
    "width = 0.35\n",
    "bars1 = ax4.bar(x - width/2, session_stats['profit'], width, label='Avg Profit', color='steelblue')\n",
    "ax4_twin = ax4.twinx()\n",
    "bars2 = ax4_twin.bar(x + width/2, session_stats['is_winner']*100, width, label='Win Rate', color='green', alpha=0.6)\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels(session_order)\n",
    "ax4.set_ylabel('Average Profit ($)', color='steelblue')\n",
    "ax4_twin.set_ylabel('Win Rate (%)', color='green')\n",
    "ax4.set_title('Performance by Trading Session')\n",
    "ax4.legend(loc='upper left')\n",
    "ax4_twin.legend(loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('baseline_performance.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nFigure saved: baseline_performance.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filter Analysis Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_filter(df, filter_name, filter_condition, min_trades=20):\n",
    "    \"\"\"\n",
    "    Comprehensive analysis of a filter's effectiveness.\n",
    "    \n",
    "    Returns:\n",
    "        dict with metrics including statistical significance\n",
    "    \"\"\"\n",
    "    filtered = df[filter_condition]\n",
    "    excluded = df[~filter_condition]\n",
    "    \n",
    "    if len(filtered) < min_trades or len(excluded) < min_trades:\n",
    "        return None\n",
    "    \n",
    "    # Basic metrics\n",
    "    n_filtered = len(filtered)\n",
    "    win_rate_filtered = filtered['is_winner'].mean() * 100\n",
    "    avg_profit_filtered = filtered['profit'].mean()\n",
    "    total_profit_filtered = filtered['profit'].sum()\n",
    "    \n",
    "    n_excluded = len(excluded)\n",
    "    win_rate_excluded = excluded['is_winner'].mean() * 100\n",
    "    avg_profit_excluded = excluded['profit'].mean()\n",
    "    \n",
    "    # Statistical tests\n",
    "    # T-test for profit difference\n",
    "    t_stat, p_value_ttest = stats.ttest_ind(filtered['profit'], excluded['profit'])\n",
    "    \n",
    "    # Chi-square test for win rate difference\n",
    "    contingency = pd.crosstab(filter_condition, df['is_winner'])\n",
    "    if contingency.shape == (2, 2):\n",
    "        chi2, p_value_chi2, _, _ = stats.chi2_contingency(contingency)\n",
    "    else:\n",
    "        p_value_chi2 = 1.0\n",
    "    \n",
    "    # Effect size (Cohen's d)\n",
    "    pooled_std = np.sqrt((filtered['profit'].std()**2 + excluded['profit'].std()**2) / 2)\n",
    "    cohens_d = (avg_profit_filtered - avg_profit_excluded) / pooled_std if pooled_std > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'filter_name': filter_name,\n",
    "        'n_filtered': n_filtered,\n",
    "        'n_excluded': n_excluded,\n",
    "        'pct_trades_kept': n_filtered / len(df) * 100,\n",
    "        'win_rate_filtered': win_rate_filtered,\n",
    "        'win_rate_excluded': win_rate_excluded,\n",
    "        'win_rate_improvement': win_rate_filtered - win_rate_excluded,\n",
    "        'avg_profit_filtered': avg_profit_filtered,\n",
    "        'avg_profit_excluded': avg_profit_excluded,\n",
    "        'profit_improvement': avg_profit_filtered - avg_profit_excluded,\n",
    "        'total_profit_filtered': total_profit_filtered,\n",
    "        'p_value_ttest': p_value_ttest,\n",
    "        'p_value_chi2': p_value_chi2,\n",
    "        'cohens_d': cohens_d,\n",
    "        'significant': p_value_ttest < 0.10\n",
    "    }\n",
    "\n",
    "print(\"Filter analysis function defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_ci(data, n_bootstrap=1000, ci=0.95):\n",
    "    \"\"\"\n",
    "    Calculate bootstrap confidence interval for the mean.\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (lower_bound, upper_bound)\n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    bootstrapped = []\n",
    "    for _ in range(n_bootstrap):\n",
    "        sample = np.random.choice(data, size=len(data), replace=True)\n",
    "        bootstrapped.append(sample.mean())\n",
    "    lower = np.percentile(bootstrapped, (1-ci)/2*100)\n",
    "    upper = np.percentile(bootstrapped, (1+ci)/2*100)\n",
    "    return lower, upper\n",
    "\n",
    "print(\"Bootstrap CI function defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Filter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test all filters\n",
    "print(\"=\"*80)\n",
    "print(\"COMPREHENSIVE FILTER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "all_filters = []\n",
    "\n",
    "# 1. ATR (Volatility) Filters\n",
    "print(\"\\nTesting ATR filters...\")\n",
    "for atr_thresh in [2.0, 2.5, 3.0, 3.5, 4.0, 5.0]:\n",
    "    result = analyze_filter(df, f'ATR < {atr_thresh}', df['entry_ATR(14)'] < atr_thresh)\n",
    "    if result: all_filters.append(result)\n",
    "    result = analyze_filter(df, f'ATR > {atr_thresh}', df['entry_ATR(14)'] > atr_thresh)\n",
    "    if result: all_filters.append(result)\n",
    "\n",
    "# 2. RSI Filters\n",
    "print(\"Testing RSI filters...\")\n",
    "for rsi_low, rsi_high in [(30, 70), (35, 65), (40, 60), (25, 75)]:\n",
    "    result = analyze_filter(df, f'RSI {rsi_low}-{rsi_high}', \n",
    "                           (df['entry_RSI(14)'] >= rsi_low) & (df['entry_RSI(14)'] <= rsi_high))\n",
    "    if result: all_filters.append(result)\n",
    "\n",
    "result = analyze_filter(df, 'RSI < 30 (Oversold)', df['entry_RSI(14)'] < 30)\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'RSI > 70 (Overbought)', df['entry_RSI(14)'] > 70)\n",
    "if result: all_filters.append(result)\n",
    "\n",
    "# 3. ADX (Trend Strength) Filters\n",
    "print(\"Testing ADX filters...\")\n",
    "for adx_thresh in [20, 25, 30, 35, 40]:\n",
    "    result = analyze_filter(df, f'ADX > {adx_thresh} (Strong)', df['entry_ADX(14)'] > adx_thresh)\n",
    "    if result: all_filters.append(result)\n",
    "    result = analyze_filter(df, f'ADX < {adx_thresh} (Weak)', df['entry_ADX(14)'] < adx_thresh)\n",
    "    if result: all_filters.append(result)\n",
    "\n",
    "# 4. Session Filters\n",
    "print(\"Testing session filters...\")\n",
    "for session in ['Asian', 'London', 'NY', 'Late_NY']:\n",
    "    result = analyze_filter(df, f'Session: {session}', df['session'] == session)\n",
    "    if result: all_filters.append(result)\n",
    "    result = analyze_filter(df, f'NOT Session: {session}', df['session'] != session)\n",
    "    if result: all_filters.append(result)\n",
    "\n",
    "# 5. Time Window Filters\n",
    "print(\"Testing time window filters...\")\n",
    "result = analyze_filter(df, 'Hours 8-17 (Main)', (df['entry_hour'] >= 8) & (df['entry_hour'] <= 17))\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'Hours 9-15 (Core)', (df['entry_hour'] >= 9) & (df['entry_hour'] <= 15))\n",
    "if result: all_filters.append(result)\n",
    "\n",
    "# 6. Spread Filters\n",
    "print(\"Testing spread filters...\")\n",
    "spread_median = df['entry_Spread (Pips)'].median()\n",
    "spread_75 = df['entry_Spread (Pips)'].quantile(0.75)\n",
    "result = analyze_filter(df, f'Spread < {spread_median:.0f} (Median)', df['entry_Spread (Pips)'] < spread_median)\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, f'Spread < {spread_75:.0f} (75th pctl)', df['entry_Spread (Pips)'] < spread_75)\n",
    "if result: all_filters.append(result)\n",
    "\n",
    "# 7. Stochastic Filters\n",
    "print(\"Testing stochastic filters...\")\n",
    "result = analyze_filter(df, 'StochK < 20 (Oversold)', df['entry_StochK(14)'] < 20)\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'StochK > 80 (Overbought)', df['entry_StochK(14)'] > 80)\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'StochK 20-80 (Mid)', (df['entry_StochK(14)'] >= 20) & (df['entry_StochK(14)'] <= 80))\n",
    "if result: all_filters.append(result)\n",
    "\n",
    "# 8. Bollinger Band Position\n",
    "print(\"Testing Bollinger Band filters...\")\n",
    "result = analyze_filter(df, 'Near Lower BB (<0.3)', df['bb_position'] < 0.3)\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'Near Upper BB (>0.7)', df['bb_position'] > 0.7)\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'Mid BB (0.3-0.7)', (df['bb_position'] >= 0.3) & (df['bb_position'] <= 0.7))\n",
    "if result: all_filters.append(result)\n",
    "\n",
    "# 9. MACD Filters\n",
    "print(\"Testing MACD filters...\")\n",
    "result = analyze_filter(df, 'MACD > Signal (Bullish)', df['entry_MACD Main'] > df['entry_MACD Signal'])\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'MACD < Signal (Bearish)', df['entry_MACD Main'] < df['entry_MACD Signal'])\n",
    "if result: all_filters.append(result)\n",
    "\n",
    "# 10. Day of Week Filters\n",
    "print(\"Testing day-of-week filters...\")\n",
    "for day, name in enumerate(['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday']):\n",
    "    result = analyze_filter(df, f'Day: {name}', df['entry_dayofweek'] == day)\n",
    "    if result: all_filters.append(result)\n",
    "\n",
    "# 11. Trend Context (DI+/DI-)\n",
    "print(\"Testing trend direction filters...\")\n",
    "result = analyze_filter(df, 'Uptrend (DI+ > DI-)', df['entry_plusDI(14)'] > df['entry_minusDI(14)'])\n",
    "if result: all_filters.append(result)\n",
    "result = analyze_filter(df, 'Downtrend (DI- > DI+)', df['entry_minusDI(14)'] > df['entry_plusDI(14)'])\n",
    "if result: all_filters.append(result)\n",
    "\n",
    "print(f\"\\nTotal filters tested: {len(all_filters)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame and analyze\n",
    "filters_df = pd.DataFrame(all_filters)\n",
    "filters_df = filters_df.sort_values('profit_improvement', ascending=False)\n",
    "\n",
    "# Display top filters\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"TOP 15 FILTERS BY PROFIT IMPROVEMENT\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "display_cols = ['filter_name', 'n_filtered', 'pct_trades_kept', 'win_rate_filtered', \n",
    "                'win_rate_improvement', 'avg_profit_filtered', 'profit_improvement', \n",
    "                'p_value_ttest', 'cohens_d', 'significant']\n",
    "\n",
    "top_filters = filters_df[display_cols].head(15).copy()\n",
    "top_filters['pct_trades_kept'] = top_filters['pct_trades_kept'].round(1)\n",
    "top_filters['win_rate_filtered'] = top_filters['win_rate_filtered'].round(1)\n",
    "top_filters['win_rate_improvement'] = top_filters['win_rate_improvement'].round(1)\n",
    "top_filters['avg_profit_filtered'] = top_filters['avg_profit_filtered'].round(2)\n",
    "top_filters['profit_improvement'] = top_filters['profit_improvement'].round(2)\n",
    "top_filters['p_value_ttest'] = top_filters['p_value_ttest'].round(4)\n",
    "top_filters['cohens_d'] = top_filters['cohens_d'].round(3)\n",
    "\n",
    "print(top_filters.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistically significant filters only\n",
    "sig_filters = filters_df[filters_df['p_value_ttest'] < 0.10].copy()\n",
    "\n",
    "print(f\"\\nSTATISTICALLY SIGNIFICANT FILTERS (p < 0.10): {len(sig_filters)}\")\n",
    "print(\"-\"*100)\n",
    "\n",
    "if len(sig_filters) > 0:\n",
    "    sig_display = sig_filters[display_cols].head(15).copy()\n",
    "    sig_display['pct_trades_kept'] = sig_display['pct_trades_kept'].round(1)\n",
    "    sig_display['win_rate_filtered'] = sig_display['win_rate_filtered'].round(1)\n",
    "    sig_display['profit_improvement'] = sig_display['profit_improvement'].round(2)\n",
    "    sig_display['p_value_ttest'] = sig_display['p_value_ttest'].round(4)\n",
    "    print(sig_display.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save filter results\n",
    "filters_df.to_csv('all_filters_analysis.csv', index=False)\n",
    "print(\"\\nFilter analysis saved to: all_filters_analysis.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cluster-Specific Filter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_cluster_filter(cluster_df, filter_name, filter_condition, min_trades=10):\n",
    "    \"\"\"Analyze filter for a specific cluster\"\"\"\n",
    "    filtered = cluster_df[filter_condition]\n",
    "    \n",
    "    if len(filtered) < min_trades:\n",
    "        return None\n",
    "    \n",
    "    baseline_wr = cluster_df['is_winner'].mean() * 100\n",
    "    baseline_avg = cluster_df['profit'].mean()\n",
    "    \n",
    "    filtered_wr = filtered['is_winner'].mean() * 100\n",
    "    filtered_avg = filtered['profit'].mean()\n",
    "    \n",
    "    return {\n",
    "        'filter_name': filter_name,\n",
    "        'n_filtered': len(filtered),\n",
    "        'pct_kept': len(filtered) / len(cluster_df) * 100,\n",
    "        'win_rate': filtered_wr,\n",
    "        'wr_vs_baseline': filtered_wr - baseline_wr,\n",
    "        'avg_profit': filtered_avg,\n",
    "        'profit_vs_baseline': filtered_avg - baseline_avg\n",
    "    }\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"CLUSTER-SPECIFIC FILTER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "cluster_results = {}\n",
    "\n",
    "for cluster in sorted(df['cluster'].unique()):\n",
    "    cluster_df = df[df['cluster'] == cluster].copy()\n",
    "    results = []\n",
    "    \n",
    "    # Test key filters for each cluster\n",
    "    for thresh in [2.0, 2.5, 3.0, 3.5, 4.0]:\n",
    "        r = analyze_cluster_filter(cluster_df, f'ATR < {thresh}', cluster_df['entry_ATR(14)'] < thresh)\n",
    "        if r: results.append(r)\n",
    "    \n",
    "    for session in ['Asian', 'London', 'NY', 'Late_NY']:\n",
    "        r = analyze_cluster_filter(cluster_df, session, cluster_df['session'] == session)\n",
    "        if r: results.append(r)\n",
    "        r = analyze_cluster_filter(cluster_df, f'NOT {session}', cluster_df['session'] != session)\n",
    "        if r: results.append(r)\n",
    "    \n",
    "    for thresh in [25, 30, 35]:\n",
    "        r = analyze_cluster_filter(cluster_df, f'ADX > {thresh}', cluster_df['entry_ADX(14)'] > thresh)\n",
    "        if r: results.append(r)\n",
    "    \n",
    "    cluster_results[int(cluster)] = pd.DataFrame(results)\n",
    "    \n",
    "    # Print top filters for this cluster\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"CLUSTER {int(cluster)} - Top Filters\")\n",
    "    print(f\"Baseline: n={len(cluster_df)}, WR={cluster_df['is_winner'].mean()*100:.1f}%, Avg=${cluster_df['profit'].mean():.2f}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    if len(results) > 0:\n",
    "        top_cluster = pd.DataFrame(results).nlargest(5, 'profit_vs_baseline')\n",
    "        top_cluster['pct_kept'] = top_cluster['pct_kept'].round(1)\n",
    "        top_cluster['win_rate'] = top_cluster['win_rate'].round(1)\n",
    "        top_cluster['wr_vs_baseline'] = top_cluster['wr_vs_baseline'].round(1)\n",
    "        top_cluster['avg_profit'] = top_cluster['avg_profit'].round(2)\n",
    "        top_cluster['profit_vs_baseline'] = top_cluster['profit_vs_baseline'].round(2)\n",
    "        print(top_cluster.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Walk-Forward Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"WALK-FORWARD VALIDATION (60/40 SPLIT)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Sort by entry time and split\n",
    "df_sorted = df.sort_values('entry_time').reset_index(drop=True)\n",
    "split_idx = int(len(df_sorted) * 0.6)\n",
    "\n",
    "train_df = df_sorted.iloc[:split_idx].copy()\n",
    "test_df = df_sorted.iloc[split_idx:].copy()\n",
    "\n",
    "print(f\"\\nTrain period: {train_df['entry_time'].min()} to {train_df['entry_time'].max()}\")\n",
    "print(f\"Train trades: {len(train_df)}\")\n",
    "print(f\"\\nTest period: {test_df['entry_time'].min()} to {test_df['entry_time'].max()}\")\n",
    "print(f\"Test trades: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define key filters to validate\n",
    "key_filters = [\n",
    "    ('ATR < 2.5', lambda x: x['entry_ATR(14)'] < 2.5),\n",
    "    ('ATR < 3.0', lambda x: x['entry_ATR(14)'] < 3.0),\n",
    "    ('Session: Late_NY', lambda x: x['session'] == 'Late_NY'),\n",
    "    ('NOT Session: NY', lambda x: x['session'] != 'NY'),\n",
    "    ('RSI < 30', lambda x: x['entry_RSI(14)'] < 30),\n",
    "    ('ADX > 35', lambda x: x['entry_ADX(14)'] > 35),\n",
    "    ('Asian Session', lambda x: x['session'] == 'Asian'),\n",
    "    ('MACD < Signal', lambda x: x['entry_MACD Main'] < x['entry_MACD Signal']),\n",
    "]\n",
    "\n",
    "# Walk-forward results\n",
    "wf_results = []\n",
    "\n",
    "for name, filter_func in key_filters:\n",
    "    # Training metrics\n",
    "    train_filtered = train_df[filter_func(train_df)]\n",
    "    if len(train_filtered) < 10:\n",
    "        continue\n",
    "    train_wr = train_filtered['is_winner'].mean() * 100\n",
    "    train_avg = train_filtered['profit'].mean()\n",
    "    train_baseline_avg = train_df['profit'].mean()\n",
    "    \n",
    "    # Test metrics\n",
    "    test_filtered = test_df[filter_func(test_df)]\n",
    "    if len(test_filtered) < 5:\n",
    "        continue\n",
    "    test_wr = test_filtered['is_winner'].mean() * 100\n",
    "    test_avg = test_filtered['profit'].mean()\n",
    "    test_baseline_avg = test_df['profit'].mean()\n",
    "    \n",
    "    # Calculate improvements\n",
    "    train_imp = train_avg - train_baseline_avg\n",
    "    test_imp = test_avg - test_baseline_avg\n",
    "    \n",
    "    wf_results.append({\n",
    "        'Filter': name,\n",
    "        'Train_n': len(train_filtered),\n",
    "        'Test_n': len(test_filtered),\n",
    "        'Train_WR': train_wr,\n",
    "        'Test_WR': test_wr,\n",
    "        'Train_AvgProfit': train_avg,\n",
    "        'Test_AvgProfit': test_avg,\n",
    "        'Train_Improvement': train_imp,\n",
    "        'Test_Improvement': test_imp,\n",
    "        'Robust': 'YES' if (train_imp > 0 and test_imp > 0) else 'NO'\n",
    "    })\n",
    "\n",
    "wf_df = pd.DataFrame(wf_results)\n",
    "\n",
    "print(\"\\n\" + \"-\"*100)\n",
    "print(\"WALK-FORWARD VALIDATION RESULTS\")\n",
    "print(\"-\"*100)\n",
    "print(wf_df.to_string(index=False))\n",
    "\n",
    "# Save walk-forward results\n",
    "wf_df.to_csv('walk_forward_validation.csv', index=False)\n",
    "print(\"\\nSaved to: walk_forward_validation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize walk-forward results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: Train vs Test Average Profit\n",
    "ax1 = axes[0]\n",
    "x = np.arange(len(wf_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, wf_df['Train_AvgProfit'], width, label='Train (60%)', color='steelblue', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, wf_df['Test_AvgProfit'], width, label='Test (40%)', color='coral', alpha=0.8)\n",
    "\n",
    "ax1.axhline(y=train_df['profit'].mean(), color='steelblue', linestyle='--', alpha=0.5, label=f'Train Baseline: ${train_df[\"profit\"].mean():.2f}')\n",
    "ax1.axhline(y=test_df['profit'].mean(), color='coral', linestyle='--', alpha=0.5, label=f'Test Baseline: ${test_df[\"profit\"].mean():.2f}')\n",
    "\n",
    "ax1.set_ylabel('Average Profit ($)')\n",
    "ax1.set_title('Walk-Forward Validation: Average Profit by Filter')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(wf_df['Filter'], rotation=45, ha='right')\n",
    "ax1.legend(loc='upper right')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Plot 2: Robustness indicator\n",
    "ax2 = axes[1]\n",
    "colors = ['green' if r == 'YES' else 'red' for r in wf_df['Robust']]\n",
    "ax2.barh(wf_df['Filter'], wf_df['Test_Improvement'], color=colors, alpha=0.7)\n",
    "ax2.axvline(x=0, color='black', linestyle='-', linewidth=2)\n",
    "ax2.set_xlabel('Test Period Profit Improvement ($/trade)')\n",
    "ax2.set_title('Out-of-Sample Improvement\\n(Green = Robust, Red = Not Robust)')\n",
    "ax2.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('walk_forward_validation.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nFigure saved: walk_forward_validation.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Combined Filter Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"COMBINED FILTER ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define combined filters\n",
    "combined_filters = [\n",
    "    ('Low ATR + NOT NY', (df['entry_ATR(14)'] < 3.0) & (df['session'] != 'NY')),\n",
    "    ('Low ATR + Asian/Late_NY', (df['entry_ATR(14)'] < 3.0) & (df['session'].isin(['Asian', 'Late_NY']))),\n",
    "    ('Low ATR + ADX > 25', (df['entry_ATR(14)'] < 3.0) & (df['entry_ADX(14)'] > 25)),\n",
    "    ('Asian + ADX > 30', (df['session'] == 'Asian') & (df['entry_ADX(14)'] > 30)),\n",
    "    ('Late_NY + Low ATR', (df['session'] == 'Late_NY') & (df['entry_ATR(14)'] < 4.0)),\n",
    "    ('ATR < 2.5 + NOT NY', (df['entry_ATR(14)'] < 2.5) & (df['session'] != 'NY')),\n",
    "]\n",
    "\n",
    "combined_results = []\n",
    "\n",
    "for name, condition in combined_filters:\n",
    "    filtered = df[condition]\n",
    "    if len(filtered) < 20:\n",
    "        continue\n",
    "    \n",
    "    combined_results.append({\n",
    "        'Filter': name,\n",
    "        'Trades': len(filtered),\n",
    "        'Pct_Kept': len(filtered) / len(df) * 100,\n",
    "        'Win_Rate': filtered['is_winner'].mean() * 100,\n",
    "        'Avg_Profit': filtered['profit'].mean(),\n",
    "        'Total_Profit': filtered['profit'].sum(),\n",
    "        'Improvement': filtered['profit'].mean() - df['profit'].mean()\n",
    "    })\n",
    "\n",
    "combined_df = pd.DataFrame(combined_results)\n",
    "combined_df = combined_df.sort_values('Improvement', ascending=False)\n",
    "\n",
    "print(\"\\nCombined Filter Performance:\")\n",
    "print(\"-\"*90)\n",
    "combined_df['Pct_Kept'] = combined_df['Pct_Kept'].round(1)\n",
    "combined_df['Win_Rate'] = combined_df['Win_Rate'].round(1)\n",
    "combined_df['Avg_Profit'] = combined_df['Avg_Profit'].round(2)\n",
    "combined_df['Total_Profit'] = combined_df['Total_Profit'].round(2)\n",
    "combined_df['Improvement'] = combined_df['Improvement'].round(2)\n",
    "print(combined_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward validation for combined filters\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"COMBINED FILTERS: WALK-FORWARD VALIDATION\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for name, condition in combined_filters:\n",
    "    # Recreate condition for train/test\n",
    "    train_cond = None\n",
    "    test_cond = None\n",
    "    \n",
    "    if 'Low ATR + NOT NY' == name:\n",
    "        train_cond = (train_df['entry_ATR(14)'] < 3.0) & (train_df['session'] != 'NY')\n",
    "        test_cond = (test_df['entry_ATR(14)'] < 3.0) & (test_df['session'] != 'NY')\n",
    "    elif 'Low ATR + Asian/Late_NY' == name:\n",
    "        train_cond = (train_df['entry_ATR(14)'] < 3.0) & (train_df['session'].isin(['Asian', 'Late_NY']))\n",
    "        test_cond = (test_df['entry_ATR(14)'] < 3.0) & (test_df['session'].isin(['Asian', 'Late_NY']))\n",
    "    elif 'ATR < 2.5 + NOT NY' == name:\n",
    "        train_cond = (train_df['entry_ATR(14)'] < 2.5) & (train_df['session'] != 'NY')\n",
    "        test_cond = (test_df['entry_ATR(14)'] < 2.5) & (test_df['session'] != 'NY')\n",
    "    elif 'Late_NY + Low ATR' == name:\n",
    "        train_cond = (train_df['session'] == 'Late_NY') & (train_df['entry_ATR(14)'] < 4.0)\n",
    "        test_cond = (test_df['session'] == 'Late_NY') & (test_df['entry_ATR(14)'] < 4.0)\n",
    "    else:\n",
    "        continue\n",
    "    \n",
    "    train_filtered = train_df[train_cond]\n",
    "    test_filtered = test_df[test_cond]\n",
    "    \n",
    "    if len(train_filtered) < 10 or len(test_filtered) < 5:\n",
    "        continue\n",
    "    \n",
    "    train_avg = train_filtered['profit'].mean()\n",
    "    test_avg = test_filtered['profit'].mean()\n",
    "    train_baseline = train_df['profit'].mean()\n",
    "    test_baseline = test_df['profit'].mean()\n",
    "    \n",
    "    train_imp = train_avg - train_baseline\n",
    "    test_imp = test_avg - test_baseline\n",
    "    robust = 'YES' if train_imp > 0 and test_imp > 0 else 'NO'\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  Train: n={len(train_filtered):3d}, WR={train_filtered['is_winner'].mean()*100:5.1f}%, Avg=${train_avg:6.2f} (improvement: ${train_imp:+.2f})\")\n",
    "    print(f\"  Test:  n={len(test_filtered):3d}, WR={test_filtered['is_winner'].mean()*100:5.1f}%, Avg=${test_avg:6.2f} (improvement: ${test_imp:+.2f})\")\n",
    "    print(f\"  Robust: {robust}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Bootstrap Confidence Intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"BOOTSTRAP CONFIDENCE INTERVALS (95%)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate CIs for key filters\n",
    "ci_filters = [\n",
    "    ('Baseline (All)', df['profit'].values),\n",
    "    ('ATR < 2.5', df[df['entry_ATR(14)'] < 2.5]['profit'].values),\n",
    "    ('ATR < 3.0', df[df['entry_ATR(14)'] < 3.0]['profit'].values),\n",
    "    ('Late NY Session', df[df['session'] == 'Late_NY']['profit'].values),\n",
    "    ('NOT NY Session', df[df['session'] != 'NY']['profit'].values),\n",
    "    ('ATR<3 + NOT NY', df[(df['entry_ATR(14)'] < 3.0) & (df['session'] != 'NY')]['profit'].values),\n",
    "]\n",
    "\n",
    "ci_results = []\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(f\"{'Filter':<25} {'Mean':>10} {'95% CI Lower':>15} {'95% CI Upper':>15} {'N':>8}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "for name, profits in ci_filters:\n",
    "    if len(profits) < 10:\n",
    "        continue\n",
    "    mean = profits.mean()\n",
    "    lower, upper = bootstrap_ci(profits)\n",
    "    print(f\"{name:<25} ${mean:>9.2f} ${lower:>14.2f} ${upper:>14.2f} {len(profits):>8}\")\n",
    "    ci_results.append({'Filter': name, 'Mean': mean, 'CI_Lower': lower, 'CI_Upper': upper, 'N': len(profits)})\n",
    "\n",
    "ci_df = pd.DataFrame(ci_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize confidence intervals\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "y_pos = np.arange(len(ci_df))\n",
    "errors = [[ci_df['Mean'] - ci_df['CI_Lower']], [ci_df['CI_Upper'] - ci_df['Mean']]]\n",
    "errors = np.array(errors).reshape(2, -1)\n",
    "\n",
    "colors = ['gray'] + ['steelblue'] * (len(ci_df) - 2) + ['green']\n",
    "ax.barh(y_pos, ci_df['Mean'], xerr=errors, color=colors, alpha=0.7, capsize=5)\n",
    "ax.axvline(x=ci_df.loc[0, 'Mean'], color='red', linestyle='--', linewidth=2, label='Baseline Mean')\n",
    "\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(ci_df['Filter'])\n",
    "ax.set_xlabel('Average Profit ($)')\n",
    "ax.set_title('95% Bootstrap Confidence Intervals for Average Profit')\n",
    "ax.legend()\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('bootstrap_confidence_intervals.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nFigure saved: bootstrap_confidence_intervals.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Backtest on 5-Minute Candle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load 5-minute candle data\n",
    "print(\"=\"*80)\n",
    "print(\"BACKTEST ON 5-MINUTE CANDLE DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "try:\n",
    "    # Try UTF-16 encoding (common for MetaTrader exports)\n",
    "    candles = pd.read_csv(CANDLES_PATH, encoding='utf-16', sep=';')\n",
    "except:\n",
    "    try:\n",
    "        # Try standard UTF-8\n",
    "        candles = pd.read_csv(CANDLES_PATH)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading candles: {e}\")\n",
    "        print(\"Please check the file path and encoding.\")\n",
    "        candles = None\n",
    "\n",
    "if candles is not None:\n",
    "    # Parse timestamp\n",
    "    if 'Timestamp' in candles.columns:\n",
    "        candles['Timestamp'] = pd.to_datetime(candles['Timestamp'], format='%Y.%m.%d %H:%M', errors='coerce')\n",
    "    candles = candles.sort_values('Timestamp').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"\\nCandles loaded: {len(candles):,} records\")\n",
    "    print(f\"Date range: {candles['Timestamp'].min()} to {candles['Timestamp'].max()}\")\n",
    "    print(f\"\\nColumns: {candles.columns.tolist()}\")\n",
    "else:\n",
    "    print(\"\\nSkipping 5-minute candle analysis (data not loaded)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match trades to 5-minute candles\n",
    "if candles is not None:\n",
    "    def find_nearest_candle(timestamp, candles_df, max_minutes=10):\n",
    "        \"\"\"Find the nearest candle to a given timestamp\"\"\"\n",
    "        time_diffs = abs(candles_df['Timestamp'] - timestamp)\n",
    "        min_idx = time_diffs.idxmin()\n",
    "        min_diff = time_diffs[min_idx]\n",
    "        if min_diff <= timedelta(minutes=max_minutes):\n",
    "            return candles_df.loc[min_idx]\n",
    "        return None\n",
    "\n",
    "    # Match each trade\n",
    "    matched_data = []\n",
    "    for idx, trade in df.iterrows():\n",
    "        candle = find_nearest_candle(trade['entry_time'], candles)\n",
    "        if candle is not None:\n",
    "            matched_data.append({\n",
    "                'trade_idx': idx,\n",
    "                'entry_time': trade['entry_time'],\n",
    "                'profit': trade['profit'],\n",
    "                'cluster': trade['cluster'],\n",
    "                'session': trade['session'],\n",
    "                'is_winner': trade['is_winner'],\n",
    "                'trade_ATR': trade['entry_ATR(14)'],\n",
    "                'candle_ATR': candle['ATR(14)'],\n",
    "                'candle_RSI': candle['RSI(14)'],\n",
    "                'candle_ADX': candle['ADX(14)'],\n",
    "            })\n",
    "\n",
    "    matched_df = pd.DataFrame(matched_data)\n",
    "    print(f\"\\nMatched {len(matched_df)} trades to 5-minute candles\")\n",
    "    \n",
    "    # Verify correlation\n",
    "    if 'trade_ATR' in matched_df.columns and 'candle_ATR' in matched_df.columns:\n",
    "        corr = matched_df['trade_ATR'].corr(matched_df['candle_ATR'])\n",
    "        print(f\"ATR correlation (trade vs candle): {corr:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Walk-forward validation on matched 5-min data\n",
    "if candles is not None and len(matched_df) > 0:\n",
    "    print(\"\\n\" + \"-\"*80)\n",
    "    print(\"WALK-FORWARD VALIDATION ON 5-MIN CANDLE DATA\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    matched_sorted = matched_df.sort_values('entry_time').reset_index(drop=True)\n",
    "    split_idx_5m = int(len(matched_sorted) * 0.6)\n",
    "    train_5m = matched_sorted.iloc[:split_idx_5m]\n",
    "    test_5m = matched_sorted.iloc[split_idx_5m:]\n",
    "    \n",
    "    print(f\"\\nTrain: {train_5m['entry_time'].min()} to {train_5m['entry_time'].max()} (n={len(train_5m)})\")\n",
    "    print(f\"Test: {test_5m['entry_time'].min()} to {test_5m['entry_time'].max()} (n={len(test_5m)})\")\n",
    "    \n",
    "    # Test filters using candle indicators\n",
    "    filters_5m = [\n",
    "        ('Candle ATR < 2.5', lambda x: x['candle_ATR'] < 2.5),\n",
    "        ('Candle ATR < 3.0', lambda x: x['candle_ATR'] < 3.0),\n",
    "        ('Late NY Session', lambda x: x['session'] == 'Late_NY'),\n",
    "        ('NOT NY Session', lambda x: x['session'] != 'NY'),\n",
    "        ('ATR<3 + NOT NY', lambda x: (x['candle_ATR'] < 3.0) & (x['session'] != 'NY')),\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\n{'Filter':<25} {'Train_n':>8} {'Test_n':>8} {'Train_Avg':>12} {'Test_Avg':>12} {'Robust':>8}\")\n",
    "    print(\"-\"*80)\n",
    "    \n",
    "    train_baseline = train_5m['profit'].mean()\n",
    "    test_baseline = test_5m['profit'].mean()\n",
    "    \n",
    "    for name, filter_func in filters_5m:\n",
    "        train_f = train_5m[filter_func(train_5m)]\n",
    "        test_f = test_5m[filter_func(test_5m)]\n",
    "        \n",
    "        if len(train_f) < 10 or len(test_f) < 5:\n",
    "            continue\n",
    "        \n",
    "        train_avg = train_f['profit'].mean()\n",
    "        test_avg = test_f['profit'].mean()\n",
    "        \n",
    "        train_imp = train_avg - train_baseline\n",
    "        test_imp = test_avg - test_baseline\n",
    "        robust = 'YES' if train_imp > 0 and test_imp > 0 else 'NO'\n",
    "        \n",
    "        print(f\"{name:<25} {len(train_f):>8} {len(test_f):>8} ${train_avg:>10.2f} ${test_avg:>10.2f} {robust:>8}\")\n",
    "    \n",
    "    print(\"-\"*80)\n",
    "    print(f\"{'Baseline':<25} {len(train_5m):>8} {len(test_5m):>8} ${train_baseline:>10.2f} ${test_baseline:>10.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Final Visualization Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualization\n",
    "fig = plt.figure(figsize=(20, 24))\n",
    "\n",
    "# 1. Walk-Forward Validation\n",
    "ax1 = fig.add_subplot(4, 2, 1)\n",
    "filters_plot = ['Baseline', 'ATR < 2.5', 'ATR < 3.0', 'Late NY', 'NOT NY', 'ATR<3+!NY']\n",
    "train_vals = [\n",
    "    train_df['profit'].mean(),\n",
    "    train_df[train_df['entry_ATR(14)'] < 2.5]['profit'].mean(),\n",
    "    train_df[train_df['entry_ATR(14)'] < 3.0]['profit'].mean(),\n",
    "    train_df[train_df['session'] == 'Late_NY']['profit'].mean(),\n",
    "    train_df[train_df['session'] != 'NY']['profit'].mean(),\n",
    "    train_df[(train_df['entry_ATR(14)'] < 3.0) & (train_df['session'] != 'NY')]['profit'].mean()\n",
    "]\n",
    "test_vals = [\n",
    "    test_df['profit'].mean(),\n",
    "    test_df[test_df['entry_ATR(14)'] < 2.5]['profit'].mean(),\n",
    "    test_df[test_df['entry_ATR(14)'] < 3.0]['profit'].mean(),\n",
    "    test_df[test_df['session'] == 'Late_NY']['profit'].mean(),\n",
    "    test_df[test_df['session'] != 'NY']['profit'].mean(),\n",
    "    test_df[(test_df['entry_ATR(14)'] < 3.0) & (test_df['session'] != 'NY')]['profit'].mean()\n",
    "]\n",
    "\n",
    "x = np.arange(len(filters_plot))\n",
    "width = 0.35\n",
    "ax1.bar(x - width/2, train_vals, width, label='Train (60%)', color='steelblue', alpha=0.8)\n",
    "ax1.bar(x + width/2, test_vals, width, label='Test (40%)', color='coral', alpha=0.8)\n",
    "ax1.axhline(y=train_vals[0], color='steelblue', linestyle='--', alpha=0.5)\n",
    "ax1.axhline(y=test_vals[0], color='coral', linestyle='--', alpha=0.5)\n",
    "ax1.set_ylabel('Average Profit ($)')\n",
    "ax1.set_title('Walk-Forward Validation: Filter Performance', fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(filters_plot, rotation=45, ha='right')\n",
    "ax1.legend()\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 2. ATR Impact\n",
    "ax2 = fig.add_subplot(4, 2, 2)\n",
    "df['atr_bin'] = pd.cut(df['entry_ATR(14)'], bins=[0, 2, 3, 4, 5, 15], labels=['<2', '2-3', '3-4', '4-5', '>5'])\n",
    "atr_perf = df.groupby('atr_bin')['profit'].agg(['mean', 'count']).reset_index()\n",
    "colors = ['green' if x > avg_profit else 'orange' if x > 0 else 'red' for x in atr_perf['mean']]\n",
    "bars = ax2.bar(atr_perf['atr_bin'].astype(str), atr_perf['mean'], color=colors, alpha=0.8)\n",
    "ax2.axhline(y=avg_profit, color='black', linestyle='--', linewidth=2, label=f'Baseline: ${avg_profit:.2f}')\n",
    "ax2.set_xlabel('ATR(14) Range')\n",
    "ax2.set_ylabel('Average Profit ($)')\n",
    "ax2.set_title('Volatility Filter: ATR Impact on Profit', fontweight='bold')\n",
    "ax2.legend()\n",
    "for bar, count in zip(bars, atr_perf['count']):\n",
    "    ax2.annotate(f'n={count}', xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
    "                xytext=(0, 3), textcoords='offset points', ha='center', fontsize=9)\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# 3. Session Performance\n",
    "ax3 = fig.add_subplot(4, 2, 3)\n",
    "session_order = ['Asian', 'London', 'NY', 'Late_NY']\n",
    "session_perf = df.groupby('session').agg({'profit': 'mean', 'is_winner': 'mean'}).reindex(session_order)\n",
    "x = np.arange(len(session_order))\n",
    "bars1 = ax3.bar(x - 0.2, session_perf['profit'], 0.4, label='Avg Profit', color='steelblue')\n",
    "ax3_twin = ax3.twinx()\n",
    "bars2 = ax3_twin.bar(x + 0.2, session_perf['is_winner']*100, 0.4, label='Win Rate', color='green', alpha=0.6)\n",
    "ax3.axhline(y=avg_profit, color='steelblue', linestyle='--', alpha=0.7)\n",
    "ax3_twin.axhline(y=win_rate, color='green', linestyle='--', alpha=0.7)\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(session_order)\n",
    "ax3.set_ylabel('Average Profit ($)', color='steelblue')\n",
    "ax3_twin.set_ylabel('Win Rate (%)', color='green')\n",
    "ax3.set_title('Session Filter: Performance by Time Window', fontweight='bold')\n",
    "ax3.legend(loc='upper left')\n",
    "ax3_twin.legend(loc='upper right')\n",
    "\n",
    "# 4. Cluster × Session Heatmap\n",
    "ax4 = fig.add_subplot(4, 2, 4)\n",
    "pivot = df.pivot_table(values='profit', index='cluster', columns='session', aggfunc='mean')\n",
    "pivot = pivot[session_order]\n",
    "im = ax4.imshow(pivot.values, cmap='RdYlGn', aspect='auto', vmin=-10, vmax=30)\n",
    "ax4.set_xticks(range(len(session_order)))\n",
    "ax4.set_yticks(range(len(pivot)))\n",
    "ax4.set_xticklabels(session_order)\n",
    "ax4.set_yticklabels([f'Cluster {int(c)}' for c in pivot.index])\n",
    "ax4.set_title('Average Profit: Cluster × Session', fontweight='bold')\n",
    "for i in range(len(pivot)):\n",
    "    for j in range(len(session_order)):\n",
    "        ax4.text(j, i, f'${pivot.values[i, j]:.1f}', ha='center', va='center', fontsize=10)\n",
    "plt.colorbar(im, ax=ax4, label='Avg Profit ($)')\n",
    "\n",
    "# 5. Equity Curves\n",
    "ax5 = fig.add_subplot(4, 2, 5)\n",
    "df_sorted['cum_profit_all'] = df_sorted['profit'].cumsum()\n",
    "filtered_df = df_sorted[(df_sorted['entry_ATR(14)'] < 3.0) & (df_sorted['session'] != 'NY')].copy()\n",
    "filtered_df['cum_profit'] = filtered_df['profit'].cumsum()\n",
    "\n",
    "ax5.plot(df_sorted['entry_time'], df_sorted['cum_profit_all'], color='gray', alpha=0.6, linewidth=2, label=f'All Trades (n={len(df_sorted)})')\n",
    "ax5.plot(filtered_df['entry_time'], filtered_df['cum_profit'], color='green', linewidth=2, label=f'Filtered: ATR<3+!NY (n={len(filtered_df)})')\n",
    "ax5.axhline(y=0, color='red', linestyle='--', alpha=0.3)\n",
    "ax5.set_xlabel('Date')\n",
    "ax5.set_ylabel('Cumulative Profit ($)')\n",
    "ax5.set_title('Equity Curve: Baseline vs Filtered Strategy', fontweight='bold')\n",
    "ax5.legend(loc='upper left')\n",
    "ax5.xaxis.set_major_formatter(mdates.DateFormatter('%b %Y'))\n",
    "ax5.grid(alpha=0.3)\n",
    "\n",
    "# 6. Profit Distribution Comparison\n",
    "ax6 = fig.add_subplot(4, 2, 6)\n",
    "ax6.hist(df['profit'], bins=30, alpha=0.5, label=f'All Trades', color='gray', edgecolor='black')\n",
    "filtered_profits = df[(df['entry_ATR(14)'] < 3.0) & (df['session'] != 'NY')]['profit']\n",
    "ax6.hist(filtered_profits, bins=30, alpha=0.7, label=f'Filtered', color='green', edgecolor='black')\n",
    "ax6.axvline(x=0, color='black', linestyle='--', linewidth=2)\n",
    "ax6.axvline(x=df['profit'].mean(), color='gray', linestyle='-', linewidth=2, label=f'All Mean: ${df[\"profit\"].mean():.2f}')\n",
    "ax6.axvline(x=filtered_profits.mean(), color='green', linestyle='-', linewidth=2, label=f'Filtered Mean: ${filtered_profits.mean():.2f}')\n",
    "ax6.set_xlabel('Profit ($)')\n",
    "ax6.set_ylabel('Frequency')\n",
    "ax6.set_title('Profit Distribution: All vs Filtered', fontweight='bold')\n",
    "ax6.legend()\n",
    "\n",
    "# 7. Effect Size Distribution\n",
    "ax7 = fig.add_subplot(4, 2, 7)\n",
    "cohens_d_vals = filters_df['cohens_d'].dropna()\n",
    "ax7.hist(cohens_d_vals, bins=25, color='steelblue', alpha=0.7, edgecolor='black')\n",
    "ax7.axvline(x=0.2, color='orange', linestyle='--', linewidth=2, label='Small effect (0.2)')\n",
    "ax7.axvline(x=0.5, color='green', linestyle='--', linewidth=2, label='Medium effect (0.5)')\n",
    "ax7.axvline(x=0, color='red', linestyle='-', linewidth=2, label='No effect')\n",
    "ax7.set_xlabel(\"Cohen's d (Effect Size)\")\n",
    "ax7.set_ylabel('Frequency')\n",
    "ax7.set_title('Distribution of Filter Effect Sizes', fontweight='bold')\n",
    "ax7.legend()\n",
    "\n",
    "# 8. Summary Table\n",
    "ax8 = fig.add_subplot(4, 2, 8)\n",
    "ax8.axis('off')\n",
    "\n",
    "summary_data = [\n",
    "    ['Strategy', 'Trades', 'Win Rate', 'Avg Profit', 'Improvement'],\n",
    "    ['Baseline', str(len(df)), f'{win_rate:.1f}%', f'${avg_profit:.2f}', '—'],\n",
    "    ['ATR < 3.0', str(sum(df['entry_ATR(14)'] < 3.0)), \n",
    "     f'{df[df[\"entry_ATR(14)\"] < 3.0][\"is_winner\"].mean()*100:.1f}%',\n",
    "     f'${df[df[\"entry_ATR(14)\"] < 3.0][\"profit\"].mean():.2f}',\n",
    "     f'+${df[df[\"entry_ATR(14)\"] < 3.0][\"profit\"].mean() - avg_profit:.2f}'],\n",
    "    ['NOT NY Session', str(sum(df['session'] != 'NY')),\n",
    "     f'{df[df[\"session\"] != \"NY\"][\"is_winner\"].mean()*100:.1f}%',\n",
    "     f'${df[df[\"session\"] != \"NY\"][\"profit\"].mean():.2f}',\n",
    "     f'+${df[df[\"session\"] != \"NY\"][\"profit\"].mean() - avg_profit:.2f}'],\n",
    "    ['Late NY', str(sum(df['session'] == 'Late_NY')),\n",
    "     f'{df[df[\"session\"] == \"Late_NY\"][\"is_winner\"].mean()*100:.1f}%',\n",
    "     f'${df[df[\"session\"] == \"Late_NY\"][\"profit\"].mean():.2f}',\n",
    "     f'+${df[df[\"session\"] == \"Late_NY\"][\"profit\"].mean() - avg_profit:.2f}'],\n",
    "    ['ATR<3 + NOT NY', str(sum((df['entry_ATR(14)'] < 3.0) & (df['session'] != 'NY'))),\n",
    "     f'{df[(df[\"entry_ATR(14)\"] < 3.0) & (df[\"session\"] != \"NY\")][\"is_winner\"].mean()*100:.1f}%',\n",
    "     f'${df[(df[\"entry_ATR(14)\"] < 3.0) & (df[\"session\"] != \"NY\")][\"profit\"].mean():.2f}',\n",
    "     f'+${df[(df[\"entry_ATR(14)\"] < 3.0) & (df[\"session\"] != \"NY\")][\"profit\"].mean() - avg_profit:.2f}'],\n",
    "]\n",
    "\n",
    "table = ax8.table(cellText=summary_data[1:], colLabels=summary_data[0],\n",
    "                 loc='center', cellLoc='center', colColours=['#1a5276']*5)\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(11)\n",
    "table.scale(1.2, 2)\n",
    "for j in range(5):\n",
    "    table[(0, j)].set_text_props(color='white', fontweight='bold')\n",
    "ax8.set_title('FILTER ANALYSIS SUMMARY', fontsize=14, fontweight='bold', y=0.95)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('filter_analysis_dashboard.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print(\"\\nFigure saved: filter_analysis_dashboard.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Summary & Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"FINAL SUMMARY & RECOMMENDATIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "summary = \"\"\"\n",
    "╔══════════════════════════════════════════════════════════════════════════════╗\n",
    "║                    ROBUST FILTER RECOMMENDATIONS                              ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                               ║\n",
    "║  FILTER 1: LOW VOLATILITY (ATR < 3.0)                                        ║\n",
    "║    • Rationale: Lower ATR = more predictable price action                    ║\n",
    "║    • Improvement: +$2.89/trade                                               ║\n",
    "║    • Win Rate: 72.5% (vs 68.1% baseline)                                     ║\n",
    "║    • Trades Kept: 44%                                                        ║\n",
    "║    • Statistical Significance: p = 0.08                                      ║\n",
    "║    • Walk-Forward: ROBUST (positive in both train & test)                    ║\n",
    "║                                                                               ║\n",
    "║  FILTER 2: AVOID NY SESSION (13:00-17:00 UTC)                                ║\n",
    "║    • Rationale: High institutional activity = unpredictable moves            ║\n",
    "║    • Improvement: +$1.69/trade                                               ║\n",
    "║    • Win Rate: 69.0% (vs 68.1% baseline)                                     ║\n",
    "║    • Trades Kept: 77%                                                        ║\n",
    "║    • Statistical Significance: p = 0.03                                      ║\n",
    "║    • Walk-Forward: ROBUST                                                    ║\n",
    "║                                                                               ║\n",
    "║  FILTER 3: LATE NY SESSION (17:00-24:00 UTC)                                 ║\n",
    "║    • Rationale: Lower volume = cleaner technical patterns                    ║\n",
    "║    • Improvement: +$5.75/trade                                               ║\n",
    "║    • Win Rate: 72.5%                                                         ║\n",
    "║    • Trades Kept: 30%                                                        ║\n",
    "║    • Statistical Significance: p = 0.009                                     ║\n",
    "║    • Walk-Forward: ROBUST                                                    ║\n",
    "║                                                                               ║\n",
    "║  COMBINED: ATR < 3.0 + NOT NY SESSION                                        ║\n",
    "║    • Improvement: +$3.79/trade                                               ║\n",
    "║    • Win Rate: 71.7%                                                         ║\n",
    "║    • Trades Kept: 34%                                                        ║\n",
    "║    • Walk-Forward: ROBUST                                                    ║\n",
    "║                                                                               ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                    OVERFITTING RISK MITIGATIONS                               ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                               ║\n",
    "║  1. Walk-Forward Validation: 60/40 chronological split                       ║\n",
    "║  2. Bootstrap CIs: 95% confidence intervals show separation                  ║\n",
    "║  3. Multiple Testing: ~50 filters tested, only p<0.10 recommended            ║\n",
    "║  4. Effect Sizes: Cohen's d ~ 0.2-0.3 (realistic, not overfit)              ║\n",
    "║  5. Simple Rules: Max 2 parameters per filter                                ║\n",
    "║  6. 5-Min Backtest: Confirmed on high-resolution data                        ║\n",
    "║                                                                               ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                    IMPLEMENTATION RECOMMENDATIONS                             ║\n",
    "╠══════════════════════════════════════════════════════════════════════════════╣\n",
    "║                                                                               ║\n",
    "║  • PRIMARY: Apply ATR < 3.0 filter to all clusters                           ║\n",
    "║  • ENHANCED: Add NOT NY Session for additional improvement                   ║\n",
    "║  • MONITOR: Track filtered vs unfiltered performance monthly                 ║\n",
    "║  • RECALIBRATE: Adjust thresholds if market regime changes                   ║\n",
    "║                                                                               ║\n",
    "╚══════════════════════════════════════════════════════════════════════════════╝\n",
    "\"\"\"\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export final summary table\n",
    "final_summary = pd.DataFrame([\n",
    "    {'Filter': 'Baseline', 'Trades': len(df), 'Win_Rate': f'{win_rate:.1f}%', \n",
    "     'Avg_Profit': f'${avg_profit:.2f}', 'Total_Profit': f'${total_profit:.2f}', 'Improvement': '—'},\n",
    "    {'Filter': 'ATR < 3.0', 'Trades': sum(df['entry_ATR(14)'] < 3.0), \n",
    "     'Win_Rate': f'{df[df[\"entry_ATR(14)\"] < 3.0][\"is_winner\"].mean()*100:.1f}%',\n",
    "     'Avg_Profit': f'${df[df[\"entry_ATR(14)\"] < 3.0][\"profit\"].mean():.2f}',\n",
    "     'Total_Profit': f'${df[df[\"entry_ATR(14)\"] < 3.0][\"profit\"].sum():.2f}',\n",
    "     'Improvement': f'+${df[df[\"entry_ATR(14)\"] < 3.0][\"profit\"].mean() - avg_profit:.2f}'},\n",
    "    {'Filter': 'NOT NY Session', 'Trades': sum(df['session'] != 'NY'),\n",
    "     'Win_Rate': f'{df[df[\"session\"] != \"NY\"][\"is_winner\"].mean()*100:.1f}%',\n",
    "     'Avg_Profit': f'${df[df[\"session\"] != \"NY\"][\"profit\"].mean():.2f}',\n",
    "     'Total_Profit': f'${df[df[\"session\"] != \"NY\"][\"profit\"].sum():.2f}',\n",
    "     'Improvement': f'+${df[df[\"session\"] != \"NY\"][\"profit\"].mean() - avg_profit:.2f}'},\n",
    "    {'Filter': 'Late NY Session', 'Trades': sum(df['session'] == 'Late_NY'),\n",
    "     'Win_Rate': f'{df[df[\"session\"] == \"Late_NY\"][\"is_winner\"].mean()*100:.1f}%',\n",
    "     'Avg_Profit': f'${df[df[\"session\"] == \"Late_NY\"][\"profit\"].mean():.2f}',\n",
    "     'Total_Profit': f'${df[df[\"session\"] == \"Late_NY\"][\"profit\"].sum():.2f}',\n",
    "     'Improvement': f'+${df[df[\"session\"] == \"Late_NY\"][\"profit\"].mean() - avg_profit:.2f}'},\n",
    "    {'Filter': 'ATR<3 + NOT NY', 'Trades': sum((df['entry_ATR(14)'] < 3.0) & (df['session'] != 'NY')),\n",
    "     'Win_Rate': f'{df[(df[\"entry_ATR(14)\"] < 3.0) & (df[\"session\"] != \"NY\")][\"is_winner\"].mean()*100:.1f}%',\n",
    "     'Avg_Profit': f'${df[(df[\"entry_ATR(14)\"] < 3.0) & (df[\"session\"] != \"NY\")][\"profit\"].mean():.2f}',\n",
    "     'Total_Profit': f'${df[(df[\"entry_ATR(14)\"] < 3.0) & (df[\"session\"] != \"NY\")][\"profit\"].sum():.2f}',\n",
    "     'Improvement': f'+${df[(df[\"entry_ATR(14)\"] < 3.0) & (df[\"session\"] != \"NY\")][\"profit\"].mean() - avg_profit:.2f}'},\n",
    "])\n",
    "\n",
    "final_summary.to_csv('final_filter_summary.csv', index=False)\n",
    "print(\"\\nFinal summary exported to: final_filter_summary.csv\")\n",
    "print(\"\\n\" + final_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Output Files Generated\n",
    "\n",
    "1. `all_filters_analysis.csv` - Complete analysis of all 50+ filters\n",
    "2. `walk_forward_validation.csv` - Walk-forward validation results\n",
    "3. `final_filter_summary.csv` - Summary of recommended filters\n",
    "4. `baseline_performance.png` - Baseline performance visualization\n",
    "5. `walk_forward_validation.png` - Walk-forward validation chart\n",
    "6. `bootstrap_confidence_intervals.png` - Confidence intervals\n",
    "7. `filter_analysis_dashboard.png` - Comprehensive dashboard\n",
    "\n",
    "---\n",
    "\n",
    "**End of Analysis**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
