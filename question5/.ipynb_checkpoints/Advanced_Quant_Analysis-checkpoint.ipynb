{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5596b569",
   "metadata": {},
   "source": [
    "# Advanced Quantitative Risk Analysis\n",
    "\n",
    "This notebook implements the complete quantitative methods for portfolio risk analysis:\n",
    "\n",
    "1. **Linear Factor Model per Cluster** (OLS Regression)\n",
    "2. **Risk Decomposition** (Variance & Expected Shortfall)\n",
    "3. **Marginal Contribution to Risk (MCR)**\n",
    "4. **Total Contribution to Risk (TCR)**\n",
    "5. **Portfolio Weight Optimization** (Markowitz / Sharpe Maximization)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa15bfce",
   "metadata": {},
   "source": [
    "Advanced Risk Analysis: Complete Quantitative Methods\n",
    "=====================================================\n",
    "Includes:\n",
    "- Linear Factor Model per Cluster (OLS Regression)\n",
    "- Risk Decomposition (Variance & Expected Shortfall)\n",
    "- Marginal Contribution to Risk (MCR)\n",
    "- Total Contribution to Risk (TCR)\n",
    "- Portfolio Weight Optimization (Markowitz / Sharpe Maximization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98539b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"ADVANCED QUANTITATIVE RISK ANALYSIS\")\n",
    "print(\"=\" * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd3400f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d2deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "\n",
    "# Load daily PnL data\n",
    "daily_pnl = pd.read_csv('/home/claude/risk_analysis/daily_pnl_per_cluster.csv', index_col=0, parse_dates=True)\n",
    "trades_df = pd.read_csv('/mnt/user-data/uploads/trades_with_clusters.csv')\n",
    "trades_df['entry_time'] = pd.to_datetime(trades_df['entry_time'])\n",
    "trades_df['exit_time'] = pd.to_datetime(trades_df['exit_time'])\n",
    "\n",
    "cluster_cols = [col for col in daily_pnl.columns if 'cluster' in col and 'total' not in col]\n",
    "cluster_pnl = daily_pnl[cluster_cols]\n",
    "\n",
    "print(f\"\\nLoaded {len(daily_pnl)} trading days, {len(cluster_cols)} clusters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f726e9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 1: LINEAR FACTOR MODEL PER CLUSTER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db0e564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SECTION 1: LINEAR FACTOR MODEL PER CLUSTER\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Build daily factor returns from trade data\n",
    "# For each date, compute average market conditions\n",
    "\n",
    "trades_df['date'] = trades_df['exit_time'].dt.floor('D')\n",
    "\n",
    "# Create daily factors\n",
    "daily_factors = trades_df.groupby('date').agg({\n",
    "    'entry_ATR(14)': 'mean',      # Volatility factor\n",
    "    'entry_ADX(14)': 'mean',      # Trend strength factor\n",
    "    'entry_RSI(14)': 'mean',      # Momentum factor\n",
    "    'entry_Close': 'last',        # For market return calculation\n",
    "    'profit': 'sum'               # Total daily profit (as market proxy)\n",
    "}).rename(columns={\n",
    "    'entry_ATR(14)': 'F_vol',\n",
    "    'entry_ADX(14)': 'F_trend', \n",
    "    'entry_RSI(14)': 'F_momentum',\n",
    "    'entry_Close': 'close',\n",
    "    'profit': 'total_pnl'\n",
    "})\n",
    "\n",
    "# Calculate market return factor (daily change in gold price)\n",
    "daily_factors['F_mkt'] = daily_factors['close'].pct_change() * 100  # In percentage\n",
    "\n",
    "# Merge with daily PnL (rename overlapping column)\n",
    "daily_factors = daily_factors.rename(columns={'total_pnl': 'factor_total_pnl'})\n",
    "analysis_df = daily_pnl.join(daily_factors, how='inner')\n",
    "analysis_df = analysis_df.dropna()\n",
    "\n",
    "print(f\"\\nFactor Analysis Dataset: {len(analysis_df)} observations\")\n",
    "print(f\"Factors: F_mkt (Market Return), F_vol (ATR), F_trend (ADX), F_momentum (RSI)\")\n",
    "\n",
    "# Run OLS regression for each cluster\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"OLS REGRESSION RESULTS: r_c,t = α + β_mkt*F_mkt + β_vol*F_vol + β_trend*F_trend + ε\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "factor_results = {}\n",
    "\n",
    "for cluster in cluster_cols:\n",
    "    # Prepare regression data\n",
    "    y = analysis_df[cluster]\n",
    "    X = analysis_df[['F_mkt', 'F_vol', 'F_trend']]\n",
    "    X = sm.add_constant(X)  # Add intercept\n",
    "    \n",
    "    # Fit OLS model\n",
    "    model = sm.OLS(y, X).fit()\n",
    "    \n",
    "    factor_results[cluster] = {\n",
    "        'alpha': model.params['const'],\n",
    "        'beta_mkt': model.params['F_mkt'],\n",
    "        'beta_vol': model.params['F_vol'],\n",
    "        'beta_trend': model.params['F_trend'],\n",
    "        'r_squared': model.rsquared,\n",
    "        'p_value_mkt': model.pvalues['F_mkt'],\n",
    "        'p_value_vol': model.pvalues['F_vol'],\n",
    "        'p_value_trend': model.pvalues['F_trend'],\n",
    "        'residual_std': model.resid.std()\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{cluster.replace('_pnl', '').upper()}:\")\n",
    "    print(f\"  α (Alpha/Intercept): {model.params['const']:.4f}\")\n",
    "    print(f\"  β_mkt (Market Beta): {model.params['F_mkt']:.4f} (p={model.pvalues['F_mkt']:.4f})\")\n",
    "    print(f\"  β_vol (Volatility Beta): {model.params['F_vol']:.4f} (p={model.pvalues['F_vol']:.4f})\")\n",
    "    print(f\"  β_trend (Trend Beta): {model.params['F_trend']:.4f} (p={model.pvalues['F_trend']:.4f})\")\n",
    "    print(f\"  R² (Explained Variance): {model.rsquared:.4f}\")\n",
    "    print(f\"  Residual Std (Idiosyncratic Risk): {model.resid.std():.4f}\")\n",
    "\n",
    "# Create factor loadings DataFrame\n",
    "factor_df = pd.DataFrame(factor_results).T\n",
    "factor_df.to_csv('/home/claude/risk_analysis/factor_model_results.csv')\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"FACTOR MODEL INTERPRETATION:\")\n",
    "print(\"-\" * 100)\n",
    "print(\"\"\"\n",
    "• β_mkt > 0: Cluster profits when gold price rises (long bias)\n",
    "• β_mkt < 0: Cluster profits when gold price falls (short bias)\n",
    "• β_vol > 0: Cluster profits in high volatility\n",
    "• β_vol < 0: Cluster profits in low volatility (range trading)\n",
    "• β_trend > 0: Cluster profits in trending markets (high ADX)\n",
    "• β_trend < 0: Cluster profits in ranging markets (low ADX)\n",
    "• α (Alpha): Risk-adjusted excess return not explained by factors\n",
    "• R²: How much of the cluster's variance is explained by factors\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67377863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 2: RISK DECOMPOSITION (VARIANCE & EXPECTED SHORTFALL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37653a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SECTION 2: RISK DECOMPOSITION (VARIANCE & EXPECTED SHORTFALL)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Covariance matrix\n",
    "cov_matrix = cluster_pnl.cov().values\n",
    "mean_returns = cluster_pnl.mean().values\n",
    "n_clusters = len(cluster_cols)\n",
    "\n",
    "# Equal weights baseline\n",
    "weights = np.array([1/n_clusters] * n_clusters)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"2.1 VARIANCE DECOMPOSITION\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Portfolio variance\n",
    "portfolio_variance = weights.T @ cov_matrix @ weights\n",
    "portfolio_std = np.sqrt(portfolio_variance)\n",
    "\n",
    "print(f\"\\nEqual-Weighted Portfolio:\")\n",
    "print(f\"  Portfolio Variance: {portfolio_variance:.4f}\")\n",
    "print(f\"  Portfolio Std Dev (σ_p): {portfolio_std:.4f}\")\n",
    "\n",
    "# Marginal Contribution to Risk (MCR)\n",
    "# MCR_i = ∂σ_p/∂w_i = (Σw)_i / σ_p\n",
    "mcr = (cov_matrix @ weights) / portfolio_std\n",
    "\n",
    "print(f\"\\n  Marginal Contribution to Risk (MCR_i = ∂σ_p/∂w_i):\")\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: {mcr[i]:.4f}\")\n",
    "\n",
    "# Total Contribution to Risk (TCR)\n",
    "# TCR_i = w_i * MCR_i\n",
    "tcr = weights * mcr\n",
    "tcr_pct = (tcr / portfolio_std) * 100\n",
    "\n",
    "print(f\"\\n  Total Contribution to Risk (TCR_i = w_i × MCR_i):\")\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: {tcr[i]:.4f} ({tcr_pct[i]:.2f}% of portfolio risk)\")\n",
    "\n",
    "print(f\"\\n  Verification: Σ TCR = {tcr.sum():.4f} (should equal σ_p = {portfolio_std:.4f})\")\n",
    "\n",
    "# Variance contribution (squared)\n",
    "var_contrib = weights * (cov_matrix @ weights)\n",
    "var_contrib_pct = (var_contrib / portfolio_variance) * 100\n",
    "\n",
    "print(f\"\\n  Variance Contribution (for decomposition):\")\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: {var_contrib[i]:.4f} ({var_contrib_pct[i]:.2f}% of portfolio variance)\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"2.2 EXPECTED SHORTFALL (CVaR) DECOMPOSITION\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Calculate portfolio daily returns\n",
    "portfolio_returns = (cluster_pnl * weights).sum(axis=1)\n",
    "\n",
    "# Calculate VaR and ES at different confidence levels\n",
    "for conf in [0.95, 0.99]:\n",
    "    var = -np.percentile(portfolio_returns, (1 - conf) * 100)\n",
    "    tail_returns = portfolio_returns[portfolio_returns <= -var]\n",
    "    es = -tail_returns.mean() if len(tail_returns) > 0 else var\n",
    "    \n",
    "    print(f\"\\n  Confidence Level: {conf*100:.0f}%\")\n",
    "    print(f\"    VaR: ${var:.2f} (worst {(1-conf)*100:.0f}% daily loss)\")\n",
    "    print(f\"    Expected Shortfall (CVaR): ${es:.2f} (average loss in worst {(1-conf)*100:.0f}% of days)\")\n",
    "\n",
    "# Component ES - contribution of each cluster to portfolio ES\n",
    "print(f\"\\n  Component Expected Shortfall (ES contribution by cluster):\")\n",
    "\n",
    "# Find worst 5% of days\n",
    "threshold = np.percentile(portfolio_returns, 5)\n",
    "worst_days = portfolio_returns <= threshold\n",
    "worst_day_indices = portfolio_returns[worst_days].index\n",
    "\n",
    "# Calculate average contribution of each cluster during worst days\n",
    "cluster_es_contrib = []\n",
    "for cluster in cluster_cols:\n",
    "    cluster_worst = cluster_pnl.loc[worst_day_indices, cluster]\n",
    "    contrib = cluster_worst.mean() * weights[cluster_cols.index(cluster)]\n",
    "    cluster_es_contrib.append(contrib)\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: ${abs(contrib):.2f} contribution to ES\")\n",
    "\n",
    "total_component_es = sum(cluster_es_contrib)\n",
    "print(f\"\\n  Total Component ES: ${abs(total_component_es):.2f}\")\n",
    "\n",
    "# Save decomposition results\n",
    "decomp_results = pd.DataFrame({\n",
    "    'Cluster': [c.replace('_pnl', '') for c in cluster_cols],\n",
    "    'Weight': weights,\n",
    "    'MCR': mcr,\n",
    "    'TCR': tcr,\n",
    "    'TCR_Pct': tcr_pct,\n",
    "    'Variance_Contrib': var_contrib,\n",
    "    'Variance_Contrib_Pct': var_contrib_pct,\n",
    "    'ES_Contrib': cluster_es_contrib\n",
    "})\n",
    "decomp_results.to_csv('/home/claude/risk_analysis/risk_decomposition_detailed.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886c8270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 3: PORTFOLIO OPTIMIZATION (MARKOWITZ / SHARPE MAXIMIZATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdae268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"SECTION 3: PORTFOLIO OPTIMIZATION (MARKOWITZ / SHARPE MAXIMIZATION)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"3.1 MAXIMUM SHARPE RATIO PORTFOLIO (Tangency Portfolio)\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "def neg_sharpe_ratio(weights, mean_returns, cov_matrix, risk_free=0):\n",
    "    \"\"\"Negative Sharpe ratio for minimization\"\"\"\n",
    "    portfolio_return = np.sum(weights * mean_returns)\n",
    "    portfolio_std = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "    sharpe = (portfolio_return - risk_free) / portfolio_std\n",
    "    return -sharpe  # Negative for minimization\n",
    "\n",
    "def portfolio_volatility(weights, cov_matrix):\n",
    "    \"\"\"Portfolio volatility\"\"\"\n",
    "    return np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "\n",
    "def portfolio_return(weights, mean_returns):\n",
    "    \"\"\"Portfolio return\"\"\"\n",
    "    return np.sum(weights * mean_returns)\n",
    "\n",
    "# Constraints\n",
    "constraints = [\n",
    "    {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}  # Weights sum to 1\n",
    "]\n",
    "\n",
    "# Bounds: long-only, max 50% per cluster\n",
    "bounds = [(0.0, 0.5) for _ in range(n_clusters)]\n",
    "\n",
    "# Initial guess\n",
    "x0 = np.array([1/n_clusters] * n_clusters)\n",
    "\n",
    "# Optimize for Maximum Sharpe\n",
    "result_sharpe = minimize(\n",
    "    neg_sharpe_ratio, \n",
    "    x0, \n",
    "    args=(mean_returns, cov_matrix, 0),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "max_sharpe_weights = result_sharpe.x\n",
    "max_sharpe_return = portfolio_return(max_sharpe_weights, mean_returns)\n",
    "max_sharpe_vol = portfolio_volatility(max_sharpe_weights, cov_matrix)\n",
    "max_sharpe_ratio = -result_sharpe.fun\n",
    "\n",
    "print(f\"\\nMaximum Sharpe Ratio Portfolio (Tangency Portfolio):\")\n",
    "print(f\"  Optimization Success: {result_sharpe.success}\")\n",
    "print(f\"\\n  Optimal Weights:\")\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: {max_sharpe_weights[i]*100:.2f}%\")\n",
    "print(f\"\\n  Portfolio Metrics:\")\n",
    "print(f\"    Expected Daily Return: ${max_sharpe_return:.4f}\")\n",
    "print(f\"    Daily Volatility: ${max_sharpe_vol:.4f}\")\n",
    "print(f\"    Daily Sharpe Ratio: {max_sharpe_ratio:.4f}\")\n",
    "print(f\"    Annualized Sharpe Ratio: {max_sharpe_ratio * np.sqrt(252):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"3.2 MINIMUM VARIANCE PORTFOLIO\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Optimize for Minimum Variance\n",
    "result_minvar = minimize(\n",
    "    portfolio_volatility,\n",
    "    x0,\n",
    "    args=(cov_matrix,),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "min_var_weights = result_minvar.x\n",
    "min_var_return = portfolio_return(min_var_weights, mean_returns)\n",
    "min_var_vol = result_minvar.fun\n",
    "min_var_sharpe = min_var_return / min_var_vol\n",
    "\n",
    "print(f\"\\nMinimum Variance Portfolio:\")\n",
    "print(f\"  Optimization Success: {result_minvar.success}\")\n",
    "print(f\"\\n  Optimal Weights:\")\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: {min_var_weights[i]*100:.2f}%\")\n",
    "print(f\"\\n  Portfolio Metrics:\")\n",
    "print(f\"    Expected Daily Return: ${min_var_return:.4f}\")\n",
    "print(f\"    Daily Volatility: ${min_var_vol:.4f}\")\n",
    "print(f\"    Daily Sharpe Ratio: {min_var_sharpe:.4f}\")\n",
    "print(f\"    Annualized Sharpe Ratio: {min_var_sharpe * np.sqrt(252):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"3.3 RISK PARITY PORTFOLIO\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "def risk_parity_objective(weights, cov_matrix):\n",
    "    \"\"\"Objective: minimize squared differences in risk contributions\"\"\"\n",
    "    weights = np.array(weights)\n",
    "    portfolio_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "    \n",
    "    # Marginal risk contribution\n",
    "    mrc = cov_matrix @ weights\n",
    "    \n",
    "    # Risk contribution\n",
    "    rc = weights * mrc / portfolio_vol\n",
    "    \n",
    "    # Target: equal risk contribution\n",
    "    target_rc = portfolio_vol / len(weights)\n",
    "    \n",
    "    # Sum of squared deviations from target\n",
    "    return np.sum((rc - target_rc) ** 2)\n",
    "\n",
    "result_rp = minimize(\n",
    "    risk_parity_objective,\n",
    "    x0,\n",
    "    args=(cov_matrix,),\n",
    "    method='SLSQP',\n",
    "    bounds=bounds,\n",
    "    constraints=constraints\n",
    ")\n",
    "\n",
    "rp_weights = result_rp.x\n",
    "rp_return = portfolio_return(rp_weights, mean_returns)\n",
    "rp_vol = portfolio_volatility(rp_weights, cov_matrix)\n",
    "rp_sharpe = rp_return / rp_vol\n",
    "\n",
    "# Verify risk contributions\n",
    "rp_mcr = (cov_matrix @ rp_weights) / rp_vol\n",
    "rp_tcr = rp_weights * rp_mcr\n",
    "rp_tcr_pct = (rp_tcr / rp_vol) * 100\n",
    "\n",
    "print(f\"\\nRisk Parity Portfolio:\")\n",
    "print(f\"  Optimization Success: {result_rp.success}\")\n",
    "print(f\"\\n  Optimal Weights:\")\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: {rp_weights[i]*100:.2f}%\")\n",
    "print(f\"\\n  Risk Contribution (should be equal ~25% each):\")\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    print(f\"    {cluster.replace('_pnl', '')}: {rp_tcr_pct[i]:.2f}%\")\n",
    "print(f\"\\n  Portfolio Metrics:\")\n",
    "print(f\"    Expected Daily Return: ${rp_return:.4f}\")\n",
    "print(f\"    Daily Volatility: ${rp_vol:.4f}\")\n",
    "print(f\"    Daily Sharpe Ratio: {rp_sharpe:.4f}\")\n",
    "print(f\"    Annualized Sharpe Ratio: {rp_sharpe * np.sqrt(252):.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"3.4 EFFICIENT FRONTIER\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "# Generate efficient frontier\n",
    "target_returns = np.linspace(min_var_return * 0.5, max(mean_returns) * 0.8, 50)\n",
    "efficient_vols = []\n",
    "efficient_weights_list = []\n",
    "\n",
    "for target in target_returns:\n",
    "    constraints_ef = [\n",
    "        {'type': 'eq', 'fun': lambda x: np.sum(x) - 1},\n",
    "        {'type': 'eq', 'fun': lambda x, t=target: portfolio_return(x, mean_returns) - t}\n",
    "    ]\n",
    "    \n",
    "    result = minimize(\n",
    "        portfolio_volatility,\n",
    "        x0,\n",
    "        args=(cov_matrix,),\n",
    "        method='SLSQP',\n",
    "        bounds=bounds,\n",
    "        constraints=constraints_ef\n",
    "    )\n",
    "    \n",
    "    if result.success:\n",
    "        efficient_vols.append(result.fun)\n",
    "        efficient_weights_list.append(result.x)\n",
    "    else:\n",
    "        efficient_vols.append(np.nan)\n",
    "        efficient_weights_list.append(None)\n",
    "\n",
    "print(f\"\\nEfficient Frontier computed with {sum(~np.isnan(efficient_vols))} valid portfolios\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"3.5 PORTFOLIO COMPARISON SUMMARY\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    'Portfolio': ['Equal Weight', 'Max Sharpe', 'Min Variance', 'Risk Parity'],\n",
    "    'C0_Weight': [25.0, max_sharpe_weights[0]*100, min_var_weights[0]*100, rp_weights[0]*100],\n",
    "    'C1_Weight': [25.0, max_sharpe_weights[1]*100, min_var_weights[1]*100, rp_weights[1]*100],\n",
    "    'C2_Weight': [25.0, max_sharpe_weights[2]*100, min_var_weights[2]*100, rp_weights[2]*100],\n",
    "    'C3_Weight': [25.0, max_sharpe_weights[3]*100, min_var_weights[3]*100, rp_weights[3]*100],\n",
    "    'Daily_Return': [\n",
    "        portfolio_return(weights, mean_returns),\n",
    "        max_sharpe_return,\n",
    "        min_var_return,\n",
    "        rp_return\n",
    "    ],\n",
    "    'Daily_Vol': [\n",
    "        portfolio_volatility(weights, cov_matrix),\n",
    "        max_sharpe_vol,\n",
    "        min_var_vol,\n",
    "        rp_vol\n",
    "    ],\n",
    "    'Daily_Sharpe': [\n",
    "        portfolio_return(weights, mean_returns) / portfolio_volatility(weights, cov_matrix),\n",
    "        max_sharpe_ratio,\n",
    "        min_var_sharpe,\n",
    "        rp_sharpe\n",
    "    ],\n",
    "    'Ann_Sharpe': [\n",
    "        (portfolio_return(weights, mean_returns) / portfolio_volatility(weights, cov_matrix)) * np.sqrt(252),\n",
    "        max_sharpe_ratio * np.sqrt(252),\n",
    "        min_var_sharpe * np.sqrt(252),\n",
    "        rp_sharpe * np.sqrt(252)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(comparison.round(4).to_string(index=False))\n",
    "comparison.to_csv('/home/claude/risk_analysis/portfolio_optimization_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8d85b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# SECTION 4: VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9e79cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "\n",
    "# Plot 1: Factor Betas\n",
    "ax1 = axes[0, 0]\n",
    "factor_names = ['beta_mkt', 'beta_vol', 'beta_trend']\n",
    "x = np.arange(len(cluster_cols))\n",
    "width = 0.25\n",
    "for i, factor in enumerate(factor_names):\n",
    "    values = [factor_df.loc[c, factor] for c in cluster_cols]\n",
    "    ax1.bar(x + i*width - width, values, width, label=factor.replace('beta_', 'β_'), alpha=0.7)\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([c.replace('_pnl', '') for c in cluster_cols])\n",
    "ax1.set_ylabel('Factor Beta')\n",
    "ax1.set_title('Linear Factor Model: Factor Betas by Cluster', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Risk Contribution Comparison\n",
    "ax2 = axes[0, 1]\n",
    "x = np.arange(n_clusters)\n",
    "width = 0.2\n",
    "portfolios = [\n",
    "    ('Equal', tcr_pct),\n",
    "    ('Max Sharpe', (max_sharpe_weights * (cov_matrix @ max_sharpe_weights) / max_sharpe_vol) / max_sharpe_vol * 100),\n",
    "    ('Min Var', (min_var_weights * (cov_matrix @ min_var_weights) / min_var_vol) / min_var_vol * 100),\n",
    "    ('Risk Parity', rp_tcr_pct)\n",
    "]\n",
    "for i, (name, tcr_vals) in enumerate(portfolios):\n",
    "    ax2.bar(x + i*width - 1.5*width, tcr_vals, width, label=name, alpha=0.7)\n",
    "ax2.axhline(y=25, color='red', linestyle='--', alpha=0.5, label='Target 25%')\n",
    "ax2.set_xticks(x)\n",
    "ax2.set_xticklabels([c.replace('_pnl', '') for c in cluster_cols])\n",
    "ax2.set_ylabel('Risk Contribution (%)')\n",
    "ax2.set_title('Total Contribution to Risk (TCR) by Portfolio', fontsize=12, fontweight='bold')\n",
    "ax2.legend(fontsize=8)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: MCR vs Weight\n",
    "ax3 = axes[0, 2]\n",
    "ax3.scatter(weights * 100, mcr, s=100, c=['C0', 'C1', 'C2', 'C3'], alpha=0.7)\n",
    "for i, cluster in enumerate(cluster_cols):\n",
    "    ax3.annotate(cluster.replace('_pnl', ''), (weights[i]*100, mcr[i]), \n",
    "                 textcoords=\"offset points\", xytext=(5,5), fontsize=10)\n",
    "ax3.set_xlabel('Weight (%)')\n",
    "ax3.set_ylabel('Marginal Contribution to Risk (MCR)')\n",
    "ax3.set_title('MCR vs Portfolio Weight', fontsize=12, fontweight='bold')\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Efficient Frontier\n",
    "ax4 = axes[1, 0]\n",
    "# Filter valid points\n",
    "valid_idx = ~np.isnan(efficient_vols)\n",
    "valid_returns = np.array(target_returns)[valid_idx]\n",
    "valid_vols = np.array(efficient_vols)[valid_idx]\n",
    "\n",
    "ax4.plot(valid_vols, valid_returns, 'b-', linewidth=2, label='Efficient Frontier')\n",
    "ax4.scatter([portfolio_volatility(weights, cov_matrix)], [portfolio_return(weights, mean_returns)], \n",
    "            s=150, c='gray', marker='s', label='Equal Weight', zorder=5, edgecolor='black')\n",
    "ax4.scatter([max_sharpe_vol], [max_sharpe_return], \n",
    "            s=150, c='gold', marker='*', label=f'Max Sharpe ({max_sharpe_ratio*np.sqrt(252):.2f})', zorder=5, edgecolor='black')\n",
    "ax4.scatter([min_var_vol], [min_var_return], \n",
    "            s=150, c='green', marker='^', label='Min Variance', zorder=5, edgecolor='black')\n",
    "ax4.scatter([rp_vol], [rp_return], \n",
    "            s=150, c='purple', marker='o', label='Risk Parity', zorder=5, edgecolor='black')\n",
    "ax4.set_xlabel('Portfolio Volatility ($)')\n",
    "ax4.set_ylabel('Expected Daily Return ($)')\n",
    "ax4.set_title('Efficient Frontier & Optimal Portfolios', fontsize=12, fontweight='bold')\n",
    "ax4.legend(loc='lower right', fontsize=8)\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Optimal Weights Comparison\n",
    "ax5 = axes[1, 1]\n",
    "portfolios_weights = {\n",
    "    'Equal': weights * 100,\n",
    "    'Max Sharpe': max_sharpe_weights * 100,\n",
    "    'Min Var': min_var_weights * 100,\n",
    "    'Risk Parity': rp_weights * 100\n",
    "}\n",
    "x = np.arange(n_clusters)\n",
    "width = 0.2\n",
    "for i, (name, w) in enumerate(portfolios_weights.items()):\n",
    "    ax5.bar(x + i*width - 1.5*width, w, width, label=name, alpha=0.7)\n",
    "ax5.set_xticks(x)\n",
    "ax5.set_xticklabels([c.replace('_pnl', '') for c in cluster_cols])\n",
    "ax5.set_ylabel('Weight (%)')\n",
    "ax5.set_title('Portfolio Weights by Optimization Strategy', fontsize=12, fontweight='bold')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Annualized Sharpe Comparison\n",
    "ax6 = axes[1, 2]\n",
    "sharpes = [\n",
    "    (portfolio_return(weights, mean_returns) / portfolio_volatility(weights, cov_matrix)) * np.sqrt(252),\n",
    "    max_sharpe_ratio * np.sqrt(252),\n",
    "    min_var_sharpe * np.sqrt(252),\n",
    "    rp_sharpe * np.sqrt(252)\n",
    "]\n",
    "names = ['Equal Weight', 'Max Sharpe', 'Min Variance', 'Risk Parity']\n",
    "colors = ['gray', 'gold', 'green', 'purple']\n",
    "bars = ax6.bar(names, sharpes, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax6.axhline(y=sharpes[0], color='red', linestyle='--', alpha=0.5, label=f'Baseline: {sharpes[0]:.2f}')\n",
    "for bar, val in zip(bars, sharpes):\n",
    "    ax6.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, f'{val:.2f}', \n",
    "             ha='center', fontweight='bold')\n",
    "ax6.set_ylabel('Annualized Sharpe Ratio')\n",
    "ax6.set_title('Annualized Sharpe by Portfolio Strategy', fontsize=12, fontweight='bold')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/risk_analysis/advanced_quant_analysis.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\n✅ Visualization saved to: advanced_quant_analysis.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ec6a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672f6fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FINAL SUMMARY: ADVANCED QUANTITATIVE ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\"\"\n",
    "┌─────────────────────────────────────────────────────────────────────────────────────────────────┐\n",
    "│ 1. LINEAR FACTOR MODEL RESULTS                                                                  │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│ Each cluster's returns decomposed into: Market, Volatility, and Trend factors                  │\n",
    "│ • Alpha (α): Unexplained excess return - indicates pure strategy skill                         │\n",
    "│ • Factor betas show systematic exposures to market conditions                                  │\n",
    "│ • R² shows how much variance is explained by factors vs idiosyncratic risk                     │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│ 2. RISK DECOMPOSITION                                                                          │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│ Variance Decomposition:                                                                        │\n",
    "│ • MCR (Marginal Contribution to Risk): How much risk increases per unit weight                │\n",
    "│ • TCR (Total Contribution to Risk): Weight × MCR, sums to portfolio volatility               │\n",
    "│                                                                                                 │\n",
    "│ Expected Shortfall Decomposition:                                                              │\n",
    "│ • VaR 95%: Worst 5% daily loss threshold                                                       │\n",
    "│ • CVaR/ES: Average loss in worst 5% of days                                                    │\n",
    "│ • Component ES: Each cluster's contribution to tail risk                                       │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│ 3. PORTFOLIO OPTIMIZATION                                                                      │\n",
    "├─────────────────────────────────────────────────────────────────────────────────────────────────┤\n",
    "│ • Max Sharpe (Tangency Portfolio): Maximizes risk-adjusted return                             │\n",
    "│ • Minimum Variance: Lowest possible portfolio volatility                                       │\n",
    "│ • Risk Parity: Equal risk contribution from each cluster                                       │\n",
    "│                                                                                                 │\n",
    "│ BEST STRATEGY: Max Sharpe with Ann. Sharpe = \"\"\" + f\"{max_sharpe_ratio * np.sqrt(252):.2f}\" + \"\"\"                                           │\n",
    "└─────────────────────────────────────────────────────────────────────────────────────────────────┘\n",
    "\"\"\")\n",
    "\n",
    "print(\"✅ ADVANCED QUANTITATIVE ANALYSIS COMPLETED\")\n",
    "print(f\"\\nFiles saved:\")\n",
    "print(f\"  - factor_model_results.csv\")\n",
    "print(f\"  - risk_decomposition_detailed.csv\")\n",
    "print(f\"  - portfolio_optimization_results.csv\")\n",
    "print(f\"  - advanced_quant_analysis.png\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
