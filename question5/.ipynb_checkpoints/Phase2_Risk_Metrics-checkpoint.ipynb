{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598ff185",
   "metadata": {},
   "source": [
    "# Phase 2: Measure Risk for Each Cluster\n",
    "\n",
    "This notebook contains the analysis for the Risk & Portfolio Interaction study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe96de8",
   "metadata": {},
   "source": [
    "Phase 2: Measure Risk for Each Cluster\n",
    "======================================\n",
    "Goal: Quantify risk per cluster using volatility, Sharpe, drawdown, skewness, kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb3d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 2: MEASURE RISK FOR EACH CLUSTER\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load daily PnL data from Phase 1\n",
    "daily_pnl = pd.read_csv('/home/claude/risk_analysis/daily_pnl_per_cluster.csv', index_col=0, parse_dates=True)\n",
    "\n",
    "# Load original trades for additional analysis\n",
    "trades_df = pd.read_csv('/mnt/user-data/uploads/trades_with_clusters.csv')\n",
    "trades_df['entry_time'] = pd.to_datetime(trades_df['entry_time'])\n",
    "trades_df['exit_time'] = pd.to_datetime(trades_df['exit_time'])\n",
    "\n",
    "# Define cluster columns\n",
    "cluster_cols = [col for col in daily_pnl.columns if 'cluster' in col and 'total' not in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8616f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RISK METRICS CALCULATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704a3bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_max_drawdown(pnl_series):\n",
    "    \"\"\"Calculate maximum drawdown from cumulative PnL\"\"\"\n",
    "    cumulative = pnl_series.cumsum()\n",
    "    running_max = cumulative.cummax()\n",
    "    drawdown = running_max - cumulative\n",
    "    return drawdown.max()\n",
    "\n",
    "def calculate_calmar_ratio(pnl_series, annual_factor=252):\n",
    "    \"\"\"Calculate Calmar Ratio (Annual Return / Max Drawdown)\"\"\"\n",
    "    annual_return = pnl_series.mean() * annual_factor\n",
    "    max_dd = calculate_max_drawdown(pnl_series)\n",
    "    return annual_return / max_dd if max_dd != 0 else np.nan\n",
    "\n",
    "def calculate_sortino_ratio(pnl_series, target=0):\n",
    "    \"\"\"Calculate Sortino Ratio (Mean / Downside Deviation)\"\"\"\n",
    "    mean_return = pnl_series.mean()\n",
    "    downside_returns = pnl_series[pnl_series < target]\n",
    "    downside_std = np.sqrt(np.mean(downside_returns**2)) if len(downside_returns) > 0 else 0\n",
    "    return mean_return / downside_std if downside_std != 0 else np.nan\n",
    "\n",
    "def calculate_var(pnl_series, confidence=0.95):\n",
    "    \"\"\"Calculate Value at Risk (historical)\"\"\"\n",
    "    return -np.percentile(pnl_series, (1 - confidence) * 100)\n",
    "\n",
    "def calculate_cvar(pnl_series, confidence=0.95):\n",
    "    \"\"\"Calculate Conditional VaR (Expected Shortfall)\"\"\"\n",
    "    var = calculate_var(pnl_series, confidence)\n",
    "    return -pnl_series[pnl_series <= -var].mean()\n",
    "\n",
    "print(\"\\nðŸ“Š Computing Risk Metrics for Each Cluster...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "risk_metrics = {}\n",
    "\n",
    "for col in cluster_cols + ['total_pnl']:\n",
    "    series = daily_pnl[col]\n",
    "    \n",
    "    metrics = {\n",
    "        'Total PnL': series.sum(),\n",
    "        'Mean Daily PnL': series.mean(),\n",
    "        'Std Dev (Volatility)': series.std(),\n",
    "        'Sharpe Ratio (Daily)': series.mean() / series.std() if series.std() != 0 else np.nan,\n",
    "        'Annualized Sharpe': (series.mean() / series.std()) * np.sqrt(252) if series.std() != 0 else np.nan,\n",
    "        'Max Drawdown': calculate_max_drawdown(series),\n",
    "        'Calmar Ratio': calculate_calmar_ratio(series),\n",
    "        'Sortino Ratio': calculate_sortino_ratio(series),\n",
    "        'Skewness': stats.skew(series),\n",
    "        'Kurtosis': stats.kurtosis(series),\n",
    "        'VaR 95%': calculate_var(series, 0.95),\n",
    "        'CVaR 95%': calculate_cvar(series, 0.95),\n",
    "        'Hit Ratio (Days > 0)': (series > 0).mean() * 100,\n",
    "        'Best Day': series.max(),\n",
    "        'Worst Day': series.min(),\n",
    "        'Days Active': (series != 0).sum()\n",
    "    }\n",
    "    \n",
    "    risk_metrics[col] = metrics\n",
    "\n",
    "# Create DataFrame\n",
    "risk_df = pd.DataFrame(risk_metrics).T\n",
    "risk_df.index.name = 'Cluster'\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"CLUSTER RISK METRICS SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Display key metrics\n",
    "display_metrics = ['Total PnL', 'Mean Daily PnL', 'Std Dev (Volatility)', \n",
    "                   'Annualized Sharpe', 'Max Drawdown', 'Sortino Ratio',\n",
    "                   'Skewness', 'Kurtosis', 'VaR 95%', 'CVaR 95%', 'Hit Ratio (Days > 0)']\n",
    "\n",
    "print(risk_df[display_metrics].round(3).to_string())\n",
    "\n",
    "# Save risk metrics\n",
    "risk_df.to_csv('/home/claude/risk_analysis/cluster_risk_metrics.csv')\n",
    "print(f\"\\nâœ… Risk metrics saved to: cluster_risk_metrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2b6eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRADE-LEVEL RISK ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3122dc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TRADE-LEVEL RISK ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "trade_risk = {}\n",
    "for cluster in sorted(trades_df['cluster'].unique()):\n",
    "    cluster_trades = trades_df[trades_df['cluster'] == cluster]['profit']\n",
    "    \n",
    "    trade_risk[f'Cluster {int(cluster)}'] = {\n",
    "        'Trade Count': len(cluster_trades),\n",
    "        'Win Rate (%)': (cluster_trades > 0).mean() * 100,\n",
    "        'Avg Win': cluster_trades[cluster_trades > 0].mean() if (cluster_trades > 0).any() else 0,\n",
    "        'Avg Loss': cluster_trades[cluster_trades < 0].mean() if (cluster_trades < 0).any() else 0,\n",
    "        'Profit Factor': abs(cluster_trades[cluster_trades > 0].sum() / cluster_trades[cluster_trades < 0].sum()) if (cluster_trades < 0).any() and cluster_trades[cluster_trades < 0].sum() != 0 else np.nan,\n",
    "        'Max Win': cluster_trades.max(),\n",
    "        'Max Loss': cluster_trades.min(),\n",
    "        'Expectancy': cluster_trades.mean(),\n",
    "        'Std Dev': cluster_trades.std()\n",
    "    }\n",
    "\n",
    "trade_risk_df = pd.DataFrame(trade_risk).T\n",
    "print(trade_risk_df.round(2).to_string())\n",
    "\n",
    "trade_risk_df.to_csv('/home/claude/risk_analysis/trade_level_risk.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ad351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a0cb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(3, 2, figsize=(16, 18))\n",
    "\n",
    "# Plot 1: Sharpe Ratio Comparison\n",
    "ax1 = axes[0, 0]\n",
    "sharpe_data = risk_df.loc[cluster_cols, 'Annualized Sharpe']\n",
    "colors = ['green' if x > 0 else 'red' for x in sharpe_data]\n",
    "bars = ax1.bar(range(len(sharpe_data)), sharpe_data, color=colors, alpha=0.7, edgecolor='black')\n",
    "ax1.set_xticks(range(len(sharpe_data)))\n",
    "ax1.set_xticklabels([c.replace('_pnl', '') for c in sharpe_data.index])\n",
    "ax1.set_title('Annualized Sharpe Ratio by Cluster', fontsize=14, fontweight='bold')\n",
    "ax1.set_ylabel('Sharpe Ratio')\n",
    "ax1.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax1.axhline(y=1, color='green', linestyle='--', alpha=0.3, label='Sharpe = 1')\n",
    "ax1.legend()\n",
    "for bar, val in zip(bars, sharpe_data):\n",
    "    ax1.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.05, \n",
    "             f'{val:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Max Drawdown Comparison\n",
    "ax2 = axes[0, 1]\n",
    "dd_data = risk_df.loc[cluster_cols, 'Max Drawdown']\n",
    "ax2.bar(range(len(dd_data)), dd_data, color='red', alpha=0.7, edgecolor='black')\n",
    "ax2.set_xticks(range(len(dd_data)))\n",
    "ax2.set_xticklabels([c.replace('_pnl', '') for c in dd_data.index])\n",
    "ax2.set_title('Maximum Drawdown by Cluster', fontsize=14, fontweight='bold')\n",
    "ax2.set_ylabel('Max Drawdown ($)')\n",
    "for i, val in enumerate(dd_data):\n",
    "    ax2.text(i, val + 5, f'${val:.0f}', ha='center', va='bottom', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Skewness and Kurtosis\n",
    "ax3 = axes[1, 0]\n",
    "x = np.arange(len(cluster_cols))\n",
    "width = 0.35\n",
    "skew_data = risk_df.loc[cluster_cols, 'Skewness']\n",
    "kurt_data = risk_df.loc[cluster_cols, 'Kurtosis']\n",
    "bars1 = ax3.bar(x - width/2, skew_data, width, label='Skewness', color='blue', alpha=0.7)\n",
    "bars2 = ax3.bar(x + width/2, kurt_data, width, label='Kurtosis', color='orange', alpha=0.7)\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels([c.replace('_pnl', '') for c in cluster_cols])\n",
    "ax3.set_title('Skewness & Kurtosis by Cluster (Tail Risk Indicators)', fontsize=14, fontweight='bold')\n",
    "ax3.axhline(y=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "# Add interpretation\n",
    "ax3.text(0.02, 0.98, 'Negative skew = Left tail (big losses)', transform=ax3.transAxes, \n",
    "         fontsize=9, verticalalignment='top', style='italic')\n",
    "\n",
    "# Plot 4: VaR and CVaR Comparison\n",
    "ax4 = axes[1, 1]\n",
    "var_data = risk_df.loc[cluster_cols, 'VaR 95%']\n",
    "cvar_data = risk_df.loc[cluster_cols, 'CVaR 95%']\n",
    "bars1 = ax4.bar(x - width/2, var_data, width, label='VaR 95%', color='coral', alpha=0.7)\n",
    "bars2 = ax4.bar(x + width/2, cvar_data, width, label='CVaR 95%', color='darkred', alpha=0.7)\n",
    "ax4.set_xticks(x)\n",
    "ax4.set_xticklabels([c.replace('_pnl', '') for c in cluster_cols])\n",
    "ax4.set_title('Value at Risk & Expected Shortfall by Cluster', fontsize=14, fontweight='bold')\n",
    "ax4.set_ylabel('Risk ($)')\n",
    "ax4.legend()\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 5: Daily PnL Distributions\n",
    "ax5 = axes[2, 0]\n",
    "for col in cluster_cols:\n",
    "    data = daily_pnl[col][daily_pnl[col] != 0]  # Exclude zero days\n",
    "    ax5.hist(data, bins=30, alpha=0.5, label=col.replace('_pnl', ''), density=True)\n",
    "ax5.axvline(x=0, color='black', linestyle='--', alpha=0.5)\n",
    "ax5.set_title('Daily PnL Distribution (Non-Zero Days)', fontsize=14, fontweight='bold')\n",
    "ax5.set_xlabel('Daily PnL ($)')\n",
    "ax5.set_ylabel('Density')\n",
    "ax5.legend()\n",
    "ax5.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 6: Cumulative Drawdown\n",
    "ax6 = axes[2, 1]\n",
    "for col in cluster_cols:\n",
    "    cumulative = daily_pnl[col].cumsum()\n",
    "    running_max = cumulative.cummax()\n",
    "    drawdown = running_max - cumulative\n",
    "    ax6.fill_between(daily_pnl.index, 0, -drawdown, alpha=0.3, label=col.replace('_pnl', ''))\n",
    "ax6.set_title('Drawdown Over Time by Cluster', fontsize=14, fontweight='bold')\n",
    "ax6.set_xlabel('Date')\n",
    "ax6.set_ylabel('Drawdown ($)')\n",
    "ax6.legend()\n",
    "ax6.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/risk_analysis/phase2_risk_metrics.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"\\nâœ… Phase 2 visualization saved to: phase2_risk_metrics.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09fffdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KEY FINDINGS SUMMARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df08e790",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 2 KEY FINDINGS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Rank clusters by Sharpe\n",
    "sharpe_ranking = risk_df.loc[cluster_cols, 'Annualized Sharpe'].sort_values(ascending=False)\n",
    "print(\"\\nðŸ† Cluster Ranking by Sharpe Ratio:\")\n",
    "for i, (cluster, sharpe) in enumerate(sharpe_ranking.items(), 1):\n",
    "    print(f\"   {i}. {cluster.replace('_pnl', '')}: {sharpe:.3f}\")\n",
    "\n",
    "# Risk Assessment\n",
    "print(\"\\nâš ï¸  Risk Assessment:\")\n",
    "for col in cluster_cols:\n",
    "    skew = risk_df.loc[col, 'Skewness']\n",
    "    kurt = risk_df.loc[col, 'Kurtosis']\n",
    "    sharpe = risk_df.loc[col, 'Annualized Sharpe']\n",
    "    \n",
    "    risk_level = \"ðŸŸ¢ LOW\" if sharpe > 1 and skew > -0.5 else \"ðŸŸ¡ MODERATE\" if sharpe > 0.5 else \"ðŸ”´ HIGH\"\n",
    "    tail_risk = \"ðŸ”´ Significant\" if skew < -0.5 or kurt > 3 else \"ðŸŸ¢ Normal\"\n",
    "    \n",
    "    print(f\"   {col.replace('_pnl', '')}:\")\n",
    "    print(f\"      Risk Level: {risk_level}, Tail Risk: {tail_risk}\")\n",
    "    print(f\"      Skewness: {skew:.2f} {'(left tail)' if skew < 0 else '(right tail)'}\")\n",
    "\n",
    "print(\"\\nâœ… PHASE 2 COMPLETED\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
