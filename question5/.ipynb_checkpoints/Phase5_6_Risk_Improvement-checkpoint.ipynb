{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "445ce6c1",
   "metadata": {},
   "source": [
    "# Phase 5 & 6: Risk Identification & Improvement Proposals\n",
    "\n",
    "This notebook contains the analysis for the Risk & Portfolio Interaction study."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3c0480",
   "metadata": {},
   "source": [
    "Phase 5 & 6: Identify Main Sources of Risk & Propose Improvements\n",
    "=================================================================\n",
    "Goal: Synthesize findings and propose concrete risk-adjusted return improvements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4f1d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.optimize import minimize\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 5: IDENTIFY MAIN SOURCES OF RISK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Load all data\n",
    "daily_pnl = pd.read_csv('/home/claude/risk_analysis/daily_pnl_per_cluster.csv', index_col=0, parse_dates=True)\n",
    "risk_metrics = pd.read_csv('/home/claude/risk_analysis/cluster_risk_metrics.csv', index_col=0)\n",
    "correlation_matrix = pd.read_csv('/home/claude/risk_analysis/correlation_matrix.csv', index_col=0)\n",
    "trades_df = pd.read_csv('/mnt/user-data/uploads/trades_with_clusters.csv')\n",
    "\n",
    "cluster_cols = [col for col in daily_pnl.columns if 'cluster' in col and 'total' not in col]\n",
    "cluster_pnl = daily_pnl[cluster_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe3252f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPREHENSIVE RISK SOURCE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc268a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘                        MAIN SOURCES OF RISK                                  â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "1. DIRECTIONAL RISK (SINGLE-ASSET XAUUSD)\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   â€¢ All 4 clusters trade ONLY XAUUSD (Gold)\n",
    "   â€¢ Portfolio is 100% concentrated in one asset\n",
    "   â€¢ Large moves in gold affect ALL strategies simultaneously\n",
    "   â€¢ No cross-asset diversification available\n",
    "   \n",
    "   QUANTIFIED IMPACT:\n",
    "   \"\"\")\n",
    "# Calculate correlation of each cluster with total portfolio\n",
    "for col in cluster_cols:\n",
    "    corr_with_total = daily_pnl[col].corr(daily_pnl['total_pnl'])\n",
    "    print(f\"      {col.replace('_pnl', '')} corr with portfolio: {corr_with_total:.3f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "   \n",
    "2. REGIME RISK (TREND/VOLATILITY CLUSTERING)\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   â€¢ Cluster 0 & 1: Trend-following, high-ADX environments\n",
    "   â€¢ Cluster 2 & 3: Appear to work in specific market conditions\n",
    "   â€¢ Regime changes can cause multiple clusters to underperform together\n",
    "   \n",
    "   QUANTIFIED IMPACT (Sharpe by Cluster):\"\"\")\n",
    "for col in cluster_cols:\n",
    "    sharpe = risk_metrics.loc[col, 'Annualized Sharpe']\n",
    "    print(f\"      {col.replace('_pnl', '')}: {sharpe:.3f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "   \n",
    "3. CORRELATION RISK (LIMITED DIVERSIFICATION)\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   â€¢ While correlations are generally low, they can increase during stress\n",
    "   â€¢ Some cluster pairs show regime-dependent correlation spikes\n",
    "   \n",
    "   CORRELATION MATRIX:\"\"\")\n",
    "print(correlation_matrix.round(3).to_string())\n",
    "\n",
    "print(\"\"\"\n",
    "   \n",
    "4. TAIL RISK (LEFT SKEW / BIG LOSERS)\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   â€¢ Some clusters show negative skewness (left tail)\n",
    "   â€¢ Fat tails (high kurtosis) indicate extreme events\n",
    "   \n",
    "   TAIL RISK METRICS:\"\"\")\n",
    "for col in cluster_cols:\n",
    "    skew = risk_metrics.loc[col, 'Skewness']\n",
    "    kurt = risk_metrics.loc[col, 'Kurtosis']\n",
    "    cvar = risk_metrics.loc[col, 'CVaR 95%']\n",
    "    skew_status = \"âš ï¸  LEFT TAIL\" if skew < -0.5 else \"âœ“ Right tail\" if skew > 0.5 else \"~ Symmetric\"\n",
    "    print(f\"      {col.replace('_pnl', '')}: Skew={skew:.2f} {skew_status}, Kurt={kurt:.2f}, CVaR={cvar:.2f}\")\n",
    "\n",
    "print(\"\"\"\n",
    "   \n",
    "5. TIME-OF-DAY / EVENT RISK\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   â€¢ Performance varies significantly by session\n",
    "   â€¢ Certain days/times coincide with economic data releases\n",
    "   â€¢ Thin liquidity periods increase slippage risk\n",
    "   \n",
    "6. OVERLAP / LEVERAGE RISK\n",
    "   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "   â€¢ Up to 4 trades can be open simultaneously\n",
    "   â€¢ 47% of time has multiple overlapping positions\n",
    "   â€¢ During high overlap, Cluster 1 dominates (73.8%)\n",
    "   â€¢ Stacked exposure amplifies drawdowns\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403cc58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PHASE 6: IMPROVEMENT PROPOSALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aaadc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PHASE 6: PROPOSALS FOR BETTER RISK-ADJUSTED RETURN\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8557bee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 CAPITAL RE-ALLOCATION BETWEEN CLUSTERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1df5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           IMPROVEMENT 1: RE-ALLOCATE CAPITAL BETWEEN CLUSTERS                â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "# Current equal weights\n",
    "n_clusters = 4\n",
    "equal_weights = np.array([0.25, 0.25, 0.25, 0.25])\n",
    "\n",
    "# Proposed weights based on Sharpe\n",
    "sharpe_values = np.array([risk_metrics.loc[col, 'Annualized Sharpe'] for col in cluster_cols])\n",
    "sharpe_weights = sharpe_values / sharpe_values.sum()\n",
    "\n",
    "# Risk-based weights (inverse volatility)\n",
    "vol_values = np.array([risk_metrics.loc[col, 'Std Dev (Volatility)'] for col in cluster_cols])\n",
    "inv_vol_weights = (1/vol_values) / (1/vol_values).sum()\n",
    "\n",
    "print(\"Current (Equal Weight) Allocation:\")\n",
    "for i, col in enumerate(cluster_cols):\n",
    "    print(f\"   {col.replace('_pnl', '')}: {equal_weights[i]*100:.1f}%\")\n",
    "\n",
    "print(\"\\nProposed Sharpe-Based Allocation:\")\n",
    "for i, col in enumerate(cluster_cols):\n",
    "    print(f\"   {col.replace('_pnl', '')}: {sharpe_weights[i]*100:.1f}%\")\n",
    "\n",
    "print(\"\\nProposed Inverse-Volatility Allocation:\")\n",
    "for i, col in enumerate(cluster_cols):\n",
    "    print(f\"   {col.replace('_pnl', '')}: {inv_vol_weights[i]*100:.1f}%\")\n",
    "\n",
    "# Calculate portfolio metrics for different allocations\n",
    "cov_matrix = cluster_pnl.cov().values\n",
    "mean_returns = cluster_pnl.mean().values\n",
    "\n",
    "def calc_portfolio_metrics(weights):\n",
    "    port_return = np.sum(weights * mean_returns)\n",
    "    port_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "    port_sharpe = (port_return / port_vol) * np.sqrt(252) if port_vol > 0 else 0\n",
    "    return port_return, port_vol, port_sharpe\n",
    "\n",
    "# Compare allocations\n",
    "allocations = {\n",
    "    'Equal Weight': equal_weights,\n",
    "    'Sharpe-Based': sharpe_weights,\n",
    "    'Inverse-Vol': inv_vol_weights,\n",
    "    'Focus on C0+C1 (70/30)': np.array([0.40, 0.30, 0.15, 0.15])\n",
    "}\n",
    "\n",
    "print(\"\\nğŸ“Š Portfolio Performance Comparison:\")\n",
    "print(\"-\" * 70)\n",
    "print(f\"{'Allocation':<25} {'Daily Return':>12} {'Daily Vol':>12} {'Ann. Sharpe':>12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for name, weights in allocations.items():\n",
    "    ret, vol, sharpe = calc_portfolio_metrics(weights)\n",
    "    print(f\"{name:<25} ${ret:>11.2f} ${vol:>11.2f} {sharpe:>12.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c16b0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 VOLATILITY TARGETING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18921c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           IMPROVEMENT 2: VOLATILITY TARGETING PER CLUSTER                    â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "target_vol = 20  # Target daily volatility per cluster contribution\n",
    "\n",
    "print(f\"Target Daily Volatility per Cluster: ${target_vol}\")\n",
    "print(\"\\nVolatility-Targeted Weights:\")\n",
    "\n",
    "vol_target_weights = []\n",
    "for i, col in enumerate(cluster_cols):\n",
    "    cluster_vol = vol_values[i]\n",
    "    target_weight = target_vol / cluster_vol if cluster_vol > 0 else 0\n",
    "    vol_target_weights.append(target_weight)\n",
    "    print(f\"   {col.replace('_pnl', '')}: Vol={cluster_vol:.2f}, Scale Factor={target_weight:.2f}\")\n",
    "\n",
    "# Normalize to sum to 1\n",
    "vol_target_weights = np.array(vol_target_weights)\n",
    "vol_target_weights = vol_target_weights / vol_target_weights.sum()\n",
    "\n",
    "print(\"\\nNormalized Volatility-Targeted Weights:\")\n",
    "for i, col in enumerate(cluster_cols):\n",
    "    print(f\"   {col.replace('_pnl', '')}: {vol_target_weights[i]*100:.1f}%\")\n",
    "\n",
    "ret, vol, sharpe = calc_portfolio_metrics(vol_target_weights)\n",
    "print(f\"\\nPortfolio Performance with Vol-Targeting: Sharpe = {sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df01a404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 RISK PARITY OPTIMIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c52718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           IMPROVEMENT 3: RISK PARITY ALLOCATION                              â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "def risk_parity_objective(weights, cov_matrix):\n",
    "    \"\"\"Objective function for risk parity: minimize difference in risk contributions\"\"\"\n",
    "    weights = np.array(weights)\n",
    "    portfolio_vol = np.sqrt(weights.T @ cov_matrix @ weights)\n",
    "    marginal_contrib = cov_matrix @ weights\n",
    "    risk_contrib = weights * marginal_contrib / portfolio_vol\n",
    "    # We want equal risk contribution\n",
    "    target_risk = portfolio_vol / len(weights)\n",
    "    return np.sum((risk_contrib - target_risk)**2)\n",
    "\n",
    "# Optimize for risk parity\n",
    "x0 = equal_weights\n",
    "constraints = {'type': 'eq', 'fun': lambda x: np.sum(x) - 1}\n",
    "bounds = [(0.05, 0.5) for _ in range(n_clusters)]  # Min 5%, Max 50%\n",
    "\n",
    "result = minimize(risk_parity_objective, x0, args=(cov_matrix,), \n",
    "                  method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "\n",
    "risk_parity_weights = result.x\n",
    "\n",
    "print(\"Risk Parity Weights:\")\n",
    "for i, col in enumerate(cluster_cols):\n",
    "    print(f\"   {col.replace('_pnl', '')}: {risk_parity_weights[i]*100:.1f}%\")\n",
    "\n",
    "# Calculate risk contribution\n",
    "portfolio_vol_rp = np.sqrt(risk_parity_weights.T @ cov_matrix @ risk_parity_weights)\n",
    "mcr = (cov_matrix @ risk_parity_weights) / portfolio_vol_rp\n",
    "tcr = risk_parity_weights * mcr\n",
    "\n",
    "print(\"\\nRisk Contribution with Risk Parity:\")\n",
    "for i, col in enumerate(cluster_cols):\n",
    "    pct = (tcr[i] / portfolio_vol_rp) * 100\n",
    "    print(f\"   {col.replace('_pnl', '')}: {pct:.1f}% of portfolio risk\")\n",
    "\n",
    "ret, vol, sharpe = calc_portfolio_metrics(risk_parity_weights)\n",
    "print(f\"\\nPortfolio Performance with Risk Parity: Sharpe = {sharpe:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d07925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 FILTER-BASED IMPROVEMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad28c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           IMPROVEMENT 4: APPLY TRADING FILTERS                               â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Recommended Filters Based on Analysis:\n",
    "\n",
    "1. GLOBAL FILTERS (Apply to all clusters):\n",
    "   â€¢ ATR Filter: Avoid trading when ATR > 4.0 (extreme volatility)\n",
    "   â€¢ Session Filter: Reduce exposure during Asian session (00:00-08:00 UTC)\n",
    "   â€¢ Day Filter: Consider reducing exposure on Thursdays (economic data)\n",
    "\n",
    "2. PER-CLUSTER FILTERS:\n",
    "   \n",
    "   Cluster 0 (Range Trading - Best Performer):\n",
    "   â€¢ Trade during: All sessions except Asian\n",
    "   â€¢ ATR condition: ATR < 3.5 (moderate volatility)\n",
    "   â€¢ Best hours: 10:00-16:00 UTC\n",
    "   \n",
    "   Cluster 1 (Trend Following - Strong Performer):\n",
    "   â€¢ Trade during: London and NY Overlap\n",
    "   â€¢ ADX condition: ADX > 25 (confirmed trend)\n",
    "   â€¢ Duration: Allow longer holds (momentum trades)\n",
    "   \n",
    "   Cluster 2 (Breakout - Lower Performance):\n",
    "   â€¢ Reduce allocation to 10-15%\n",
    "   â€¢ Only trade with clear directional signals\n",
    "   â€¢ Tighter stops due to left-skewed returns\n",
    "   \n",
    "   Cluster 3 (Momentum - Lower Performance):\n",
    "   â€¢ Reduce allocation to 10-15%\n",
    "   â€¢ Avoid Thursday trades\n",
    "   â€¢ Session restriction: Avoid Late US session\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d8b044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5 OVERLAP CONTROLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58e377",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\"\"\n",
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "â•‘           IMPROVEMENT 5: CONTROL TRADE OVERLAP & MAX EXPOSURE                â•‘\n",
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\"\"\")\n",
    "\n",
    "print(\"\"\"\n",
    "Recommended Overlap Controls:\n",
    "\n",
    "1. MAX SIMULTANEOUS TRADES:\n",
    "   â€¢ Limit to 3 trades max at any time\n",
    "   â€¢ Current max is 4, often running 2+ trades\n",
    "\n",
    "2. MAX SAME-DIRECTION EXPOSURE:\n",
    "   â€¢ No more than 2 trades in same direction (all long or all short)\n",
    "   \n",
    "3. CLUSTER DIVERSITY REQUIREMENT:\n",
    "   â€¢ When >2 trades open, require different clusters\n",
    "   â€¢ Prevents Cluster 1 domination (currently 73.8% during overlap)\n",
    "\n",
    "4. REGIME-BASED SCALING:\n",
    "   â€¢ In high-volatility regimes: Reduce position size by 25-50%\n",
    "   â€¢ In low-ADX (ranging) markets: Favor Cluster 0, reduce Cluster 1\n",
    "\n",
    "5. TIME-BASED LIMITS:\n",
    "   â€¢ During major economic releases: No new entries\n",
    "   â€¢ During low-liquidity Asian hours: Reduce max positions to 2\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44363029",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUMMARY TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4b762",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PORTFOLIO OPTIMIZATION SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary_data = {\n",
    "    'Strategy': ['Equal Weight', 'Sharpe-Based', 'Inverse-Vol', 'Risk Parity', 'Focus C0+C1'],\n",
    "    'C0 Weight': [25.0, sharpe_weights[0]*100, inv_vol_weights[0]*100, risk_parity_weights[0]*100, 40.0],\n",
    "    'C1 Weight': [25.0, sharpe_weights[1]*100, inv_vol_weights[1]*100, risk_parity_weights[1]*100, 30.0],\n",
    "    'C2 Weight': [25.0, sharpe_weights[2]*100, inv_vol_weights[2]*100, risk_parity_weights[2]*100, 15.0],\n",
    "    'C3 Weight': [25.0, sharpe_weights[3]*100, inv_vol_weights[3]*100, risk_parity_weights[3]*100, 15.0],\n",
    "}\n",
    "\n",
    "all_weights = [equal_weights, sharpe_weights, inv_vol_weights, risk_parity_weights, \n",
    "               np.array([0.40, 0.30, 0.15, 0.15])]\n",
    "summary_data['Ann. Sharpe'] = [calc_portfolio_metrics(w)[2] for w in all_weights]\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "print(summary_df.round(2).to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('/home/claude/risk_analysis/optimization_summary.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bfa8bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e17dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
    "\n",
    "# Plot 1: Weight Comparison\n",
    "ax1 = axes[0, 0]\n",
    "x = np.arange(n_clusters)\n",
    "width = 0.15\n",
    "strategies = ['Equal', 'Sharpe', 'InvVol', 'RiskParity', 'Focus']\n",
    "colors = plt.cm.Set2(np.linspace(0, 1, 5))\n",
    "\n",
    "for i, (strat, weights) in enumerate(zip(strategies, all_weights)):\n",
    "    ax1.bar(x + i*width - 2*width, weights*100, width, label=strat, color=colors[i])\n",
    "\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels([c.replace('_pnl', '') for c in cluster_cols])\n",
    "ax1.set_ylabel('Weight (%)')\n",
    "ax1.set_title('Portfolio Weight Comparison', fontsize=14, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Sharpe Ratio Comparison\n",
    "ax2 = axes[0, 1]\n",
    "sharpe_values_all = [calc_portfolio_metrics(w)[2] for w in all_weights]\n",
    "colors_sharpe = ['green' if s > sharpe_values_all[0] else 'gray' for s in sharpe_values_all]\n",
    "bars = ax2.bar(strategies, sharpe_values_all, color=colors_sharpe, alpha=0.7, edgecolor='black')\n",
    "ax2.axhline(y=sharpe_values_all[0], color='red', linestyle='--', label=f'Baseline: {sharpe_values_all[0]:.2f}')\n",
    "ax2.set_ylabel('Annualized Sharpe Ratio')\n",
    "ax2.set_title('Portfolio Sharpe by Strategy', fontsize=14, fontweight='bold')\n",
    "ax2.legend()\n",
    "for bar, val in zip(bars, sharpe_values_all):\n",
    "    ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, f'{val:.2f}', \n",
    "             ha='center', fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Risk Contribution (Equal vs Risk Parity)\n",
    "ax3 = axes[1, 0]\n",
    "# Equal weight risk contribution\n",
    "portfolio_vol_eq = np.sqrt(equal_weights.T @ cov_matrix @ equal_weights)\n",
    "mcr_eq = (cov_matrix @ equal_weights) / portfolio_vol_eq\n",
    "tcr_eq = equal_weights * mcr_eq\n",
    "tcr_eq_pct = (tcr_eq / portfolio_vol_eq) * 100\n",
    "\n",
    "# Risk parity risk contribution\n",
    "tcr_rp_pct = (tcr / portfolio_vol_rp) * 100\n",
    "\n",
    "x = np.arange(n_clusters)\n",
    "width = 0.35\n",
    "ax3.bar(x - width/2, tcr_eq_pct, width, label='Equal Weight', color='steelblue', alpha=0.7)\n",
    "ax3.bar(x + width/2, tcr_rp_pct, width, label='Risk Parity', color='coral', alpha=0.7)\n",
    "ax3.axhline(y=25, color='black', linestyle='--', alpha=0.5, label='Target (25%)')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels([c.replace('_pnl', '') for c in cluster_cols])\n",
    "ax3.set_ylabel('Risk Contribution (%)')\n",
    "ax3.set_title('Risk Contribution: Equal vs Risk Parity', fontsize=14, fontweight='bold')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 4: Efficient Frontier Approximation\n",
    "ax4 = axes[1, 1]\n",
    "# Generate random portfolios\n",
    "np.random.seed(42)\n",
    "n_portfolios = 1000\n",
    "results = []\n",
    "for _ in range(n_portfolios):\n",
    "    w = np.random.random(n_clusters)\n",
    "    w = w / w.sum()\n",
    "    ret, vol, sharpe = calc_portfolio_metrics(w)\n",
    "    results.append((ret, vol, sharpe, w))\n",
    "\n",
    "rets = [r[0] for r in results]\n",
    "vols = [r[1] for r in results]\n",
    "sharpes = [r[2] for r in results]\n",
    "\n",
    "scatter = ax4.scatter(vols, rets, c=sharpes, cmap='viridis', alpha=0.5, s=10)\n",
    "plt.colorbar(scatter, ax=ax4, label='Sharpe')\n",
    "\n",
    "# Mark specific portfolios\n",
    "for name, weights, color, marker in [\n",
    "    ('Equal', equal_weights, 'red', 's'),\n",
    "    ('Sharpe', sharpe_weights, 'blue', '^'),\n",
    "    ('RiskParity', risk_parity_weights, 'green', 'o'),\n",
    "]:\n",
    "    ret, vol, sharpe = calc_portfolio_metrics(weights)\n",
    "    ax4.scatter(vol, ret, color=color, marker=marker, s=150, edgecolor='black', \n",
    "                label=f'{name} (SR={sharpe:.2f})', zorder=5)\n",
    "\n",
    "ax4.set_xlabel('Daily Volatility ($)')\n",
    "ax4.set_ylabel('Daily Return ($)')\n",
    "ax4.set_title('Efficient Frontier & Portfolio Strategies', fontsize=14, fontweight='bold')\n",
    "ax4.legend(loc='lower right')\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/home/claude/risk_analysis/phase5_6_optimization.png', dpi=150, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"\\nâœ… Phase 5 & 6 visualization saved to: phase5_6_optimization.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b12ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL RECOMMENDATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8863487a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL RECOMMENDATIONS FOR BETTER RISK-ADJUSTED RETURN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\"\"\n",
    "1. IMMEDIATE ACTIONS:\n",
    "   âœ“ Reduce allocation to Clusters 2 & 3 (lower Sharpe, higher tail risk)\n",
    "   âœ“ Increase allocation to Clusters 0 & 1 (higher Sharpe, better behavior)\n",
    "   âœ“ Implement max overlap limit of 3 trades\n",
    "\n",
    "2. SHORT-TERM IMPROVEMENTS:\n",
    "   âœ“ Apply volatility targeting to normalize risk contribution\n",
    "   âœ“ Implement session-based filters (reduce Asian session exposure)\n",
    "   âœ“ Add ATR-based position sizing (reduce size in high volatility)\n",
    "\n",
    "3. MEDIUM-TERM ENHANCEMENTS:\n",
    "   âœ“ Move towards risk parity allocation for balanced risk\n",
    "   âœ“ Develop regime-aware allocation rules\n",
    "   âœ“ Implement correlation monitoring for dynamic adjustment\n",
    "\n",
    "4. EXPECTED IMPROVEMENTS:\n",
    "   â€¢ Current Equal-Weight Sharpe: \"\"\" + f\"{sharpe_values_all[0]:.2f}\" + \"\"\"\n",
    "   â€¢ Projected Optimized Sharpe: \"\"\" + f\"{max(sharpe_values_all):.2f}\" + \"\"\"\n",
    "   â€¢ Estimated improvement: \"\"\" + f\"{(max(sharpe_values_all)/sharpe_values_all[0] - 1)*100:.1f}%\" + \"\"\" better risk-adjusted return\n",
    "   â€¢ Reduced maximum drawdown through overlap controls\n",
    "   â€¢ More stable returns through volatility targeting\n",
    "\"\"\")\n",
    "\n",
    "print(\"\\nâœ… PHASE 5 & 6 COMPLETED\")"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
